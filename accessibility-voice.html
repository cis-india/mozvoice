<!DOCTYPE html>
<html><!DOCTYPE html>
<html>
<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Making Voices Heard | A study by the Centre for Internet and Society, India, supported by Mozilla Corporation" />
  <!-- Title + CSS + Favicon -->
  <title>Making Voices Heard</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Header -->
  <div>
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <!-- Top Navigation Bar -->
  <div class="blue nav">
    <div class="ui container">
      <div class="nav-entries">
        <a href="index.html" id="home">Home</a> <a href="design-brief.html">Design Brief</a> <span id="inactive">Policy Brief</span> <a href="mapping-actors.html">Mapping Actors</a> <a href="#case-studies">Case Studies</a> <a href="#literature-surveys">Literature Surveys</a> <a href="#resources">Resources</a> <span id="report"><a href="docs/CIS_MakingVoicesHeard_Report.pdf"><i class="fas fa-arrow-circle-down"></i> Get Full Report</a></span>
      </div>
    </div>
  </div>
  <!-- Title -->
  <div class="grey">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column text">
        <h2>Voice Interfaces and Accessibility</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="nine wide column text">

        <h3 id="about">Background</h3>
        <p> The World Wide Web Consortium’s (W3C) Web Accessibility Initiative provided a set of guidelines in 2008 and 2018 to make the internet more accessible. It also laid down the essential components of web accessibility, one of which is assistive technologies. This includes screen readers, alternative keyboards, switches, and scanning software.<sup class="superscript"><a href="#fn1">1</a></sup><a name="ref1"></a> Before the advent of consumer voice technologies, the most popular speech-based accessibility technologies were screen readers, which provide audio output for people with visual impairments, and speech dictation software, which provide a text-entry alternative to the keyboard.</p>
        <p> The development of voice-enabled products provides the individual with the opportunity to apply speech inputs to more than just text dictation and screen reader software.<sup class="superscript"><a href="#fn2">2</a></sup><a name="ref2"></a> There has been very little research on how these applications can help people with various accessibility needs. The paucity of research could be due to the lack of funding or lack of interest from companies. Most accessibility studies focus on older adults and features such as emergency services, health monitoring, and light or temperature control. However, there has been little attention paid to how these technologies can be useful to persons with accessibility needs to perform different tasks. Despite the paucity of research, user reports show that voice-enabled devices and smart home appliances are being used by persons with disabilities (PwDs) to navigate their day-to-day activities based on speech inputs. This article explores how effective these technologies are as accessibility devices. For example, an interviewee in this study pointed out that these interfaces can be used to perform simple tasks (like relaying news or the weather) or to access entertainment (turning on YouTube or a music app), but were not effective in productivity apps (such as email dictation).</p>
        <p> From an accessibility perspective, the adoption of voice interfaces (VIs) varies depending on the type of disability. Scholars opine that VIs were picked up as assistive technologies by persons who are visually impaired.<sup class="superscript"><a href="#fn3">3</a></sup><a name="ref3"></a> However, a significant challenge in the adoption of VIs as assistive technologies is its inability to assist deaf and hard of hearing (DHH) individuals. <sup class="superscript"><a href="#fn4">4</a></sup><a name="ref4"></a> In addition to the DHH community, older people who have debilitating conditions such as dementia,<sup class="superscript"><a href="#fn5">5</a></sup><a name="ref5"></a> and people who have speech disabilities,<sup class="superscript"><a href="#fn6">6</a></sup><a name="ref6"></a> find VIs difficult to use.</p>
        <p> Despite these perceived limitations, Pradhan, A., et al. (2018)<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> conducted a qualitative study to ascertain the accessibility of VIs among PwDs<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a> with visual, locomotor, and cognitive impairments. The researchers examined 346 customer reviews of off-the-shelf digital assistants, such as Amazon Echo, Echo Dot, and Tap, and found that 85.6% of them were positive. The study highlighted that the people were using the Amazon Echo not just for the known uses but also for unexpected purposes such as speech therapy and support for caregivers. However it also emphasised that the people faced some difficulty in discovering new features, as well as wished for a better voice-only application.</p>
        <p> The next section seeks to provide a holistic overview of the opportunities and challenges that individuals with disabilities face while using VIs.</p>
<h3 id="accessibility">Accessibility benefits and concerns</h3>
<p>VIs can be beneficial to individuals who face difficulty in using text-only interfaces. Although there are multiple benefits of using VIs for performing simple to complex tasks, there is a need to look at creating devices that are universally accessible. This section will look at the benefits and concerns that come with deploying VIs as an accessibility feature for PwDs. </p>
<h4>Individuals with vision impairment or low vision</h4>
<p>VIs have made it easier for visually impaired people to perform simple, commonplace tasks to a certain extent. An empirical study of 16 participants with vision impairments revealed that there were different types of tasks that digital voice assistants could complete.<sup class="superscript"><a href="#fn9">9</a></sup><a name="ref9"></a> According to the sample, they used digital voice assistants to play music, check the weather, set a timer, and listen to the news. On the other hand, playing games, shopping online, calling contacts, playing the radio, and reading books were less common.<sup class="superscript"><a href="#fn10">10</a></sup><a name="ref10"></a> Emerging trends in smart devices and smart home appliances, such as Ambient Assisted Living (AAL),<sup class="superscript"><a href="#fn11">11</a></sup><a name="ref11"></a> offer new opportunities for people to access services through voice. According to Rashidi and Mihailidis, “AAL technologies provide help with daily activities, based on monitoring activities of daily living (ADL) and issuing reminders, as well as helping with mobility and automation”.<sup class="superscript"><a href="#fn12">12</a></sup><a name="ref12"></a> Offshoots of AAL that utilise VIs include smart home technologies, mobile wearables or sensors, and assistive robotics, among others.<sup class="superscript"><a href="#fn13">13</a></sup><a name="ref13"></a> In an empirical study, Vacher, et al. (2013) shed light on the usability of AAL for the visually impaired, the elderly, and people with no special needs. <sup class="superscript"><a href="#fn14">14</a></sup><a name="ref14"></a> They found that visually impaired participants favoured the adoption of smart home technologies, although they wished that they would render support for more complex tasks such as sending messages, emails or contacting emergency services.<sup class="superscript"><a href="#fn15">15</a></sup><a name="ref15"></a></p>
<h4>Individuals with locomotor disability</h4>
<p> Smart home appliances with VIs have the potential to be of assistance to individuals with locomotor or sensory-motor disabilities. Presently, individuals can control electronic devices and the locks of their homes through voice commands.<sup class="superscript"><a href="#fn16">16</a></sup><a name="ref16"></a> Another possible advantage of VIs is that they can be potentially used to control wheelchairs.<sup class="superscript"><a href="#fn17">17</a></sup><a name="ref17"></a> In addition, VIs such as the ‘listening keyboard’ enable locomotor-disabled individuals to provide voice inputs, rather than traditional text inputs, to their smartphones and desktops.<sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a> Research proves that a listening keyboard offers better functionality than a graphical user interface; the former has a 63% better error rate and a typing rate that is 74% better.<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a> If developed along the same lines as the ‘listening keyboard’, voice commands can also help people with limited mobility control their desktop cursors.<sup class="superscript"><a href="#fn20">20</a></sup><a name="ref20"></a></p>
<h4>Individuals who are hard of hearing</h4>
<p> Although VIs are beneficial for visually impaired and motor-impaired people , the primary accessibility challenge is for DHH individuals. According to Fok, et al., “as automatic speech recognition (ASR) systems are largely trained using speech from hearing individuals, speech-controlled technologies are typically inaccessible to deaf users”.<sup class="superscript"><a href="#fn21">21</a></sup><a name="ref21"></a> However, the outputs of some digital assistants for DHH individuals are also displayed as captions instead of voice. However, the subsequent problem with captions is that they become impossible for DHH individuals  who are not literate to interact with them.<sup class="superscript"><a href="#fn22">22</a></sup><a name="ref22"></a></p>
<p> A study revealed that a few individuals with hearing impairments who use digital assistants, faced difficulties in understanding voice outputs, although they did benefit from modifying the speech settings or pairing earphones.<sup class="superscript"><a href="#fn23">23</a></sup><a name="ref23"></a></p>
<p> In an attempt to explore alternative methods of using digital assistants, Rodolitz, et al. conducted an extensive study. The researchers considered the modality of using gesture control, as opposed to voice control, in a bid to use American Sign Language (ASL) instead of natural language in digital assistants.<sup class="superscript"><a href="#fn24">24</a></sup><a name="ref24"></a> Unfortunately, however, they found that with the current state of technology, it is unfeasible to use ASL to interact with digital assistants.<sup class="superscript"><a href="#fn25">25</a></sup><a name="ref25"></a></p>
<p>To summarise, the literature on VIs suggests that accessibility is often incorporated as an afterthought in these technologies.<sup class="superscript"><a href="#fn26">26</a></sup><a name="ref26"></a> Incorporating the needs of individuals with disabilities into the UX design process is the need of the hour.</p>
<h3 id="policy">Policy schemes for accessibility</h3>
<p> There is a shortage of technical communication research on the design of spoken language devices.<sup class="superscript"><a href="#fn27">27</a></sup><a name="ref27"></a> This lack of research translates to a lack of established standards, which is a major challenge in voice-enabled device accessibility. Significant policies promulgated in the global context to overcome this challenge include the United Nations Convention on the Rights of Persons with Disabilities (CRPD) and the World Wide Web Consortium (W3C).</p>
<p> India has also ratified the CRPD, whose Article 9(1) reads, “To enable persons with disabilities to live independently and participate fully in all aspects of life, States Parties shall take appropriate measures to ensure persons with disabilities access”.<sup class="superscript"><a href="#fn28">28</a></sup><a name="ref28"></a> The CRPD Committee promotes the use of universal design, which encourages the development of products and services for all people without the need for specialised design.<sup class="superscript"><a href="#fn29">29</a></sup><a name="ref29"></a> Consequently, the Government of India formulated the National Policy on Universal Electronic Accessibility to ensure the adoption of universal design and accessibility standards in electronics and information and communication technologies (ICTs).<sup class="superscript"><a href="#fn30">30</a></sup><a name="ref30"></a></p>
<p>One of the primary aims for formulating the CRPD and the National Policy on Universal Electronic Accessibility is ensuring the democratisation of technology. This will be achievable if interfaces are designed to be more accessible and inclusive.<sup class="superscript"><a href="#fn31">31</a></sup><a name="ref31"></a></p>
<h3 id="policy">The future of accessible voice VIs</h3>
<p>VIs have the immense potential to be of assistance to persons who are limited by solely textual interfaces. With the increased uptake of smart appliances in homes and offices, we must consider the universal accessibility of devices so that people with various accessibility needs can use them with ease.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Voice-enabled products enable people to apply speech inputs and voice commands to access a variety of services. However, there is very little research on how these applications can help people with various accessibility needs. There is also a need to ensure that not only the device, but even the website, setup, and privacy policies are designed so everyone can access it. Additionally, developers and designers of both hardware and software should look at how to make the devices accessible to people with different types of disabilities; these could be through multiple channels of input and output, tactile markers, and audio feedback. This would go a long way in ensuring that commonly used technologies, including VIs and services are universally accessible to persons with diverse accessibility needs.</p>

      </div>
      <div class="one wide column empty">
      </div>
      <div class="five wide column meta">
        <p><span id="grey">Research and Writing by</span> <br />Deepika Nandagudi Srinivasa and Shweta Mohandas
          <br />
        <span id="grey">Review and Editing by</span> <br /> Saumyaa Naidu, Puthiya Purayil Sneha, <br /><span id="grey">and</span> Pranav M.B <br />
        <span id="grey">Research Inputs by</span> <br />Sumandro Chattapadhyay<br />
	       <br />
        <a href="docs/MozVoice_PolicyBrief_02.pdf"><i class="fas fa-arrow-circle-down" style="color: black;" ></i> Download Voice Interfaces and Language
</a></p>
        <br />
         <hr />
	       <br />
        <p><span style="line-height: 3em;">CONTENTS</span></p>
	      <p><a href="#about"><strong>Background</strong></a></p>
        <p><a href="#significant"><strong>Significant challenges for multilingual support</strong></a></p>
        <p><a href="#voice"><strong>Voice initiatives to bridge the digital divide</strong></a></p>
        <p><a href="#future"><strong>Future of multilingual VIs </strong></a></p>
        <p><a href="#conclusion"><strong>Conclusion</strong></a></p>

</div>

<div class="ten wide column content">
</div>
<div class="ten wide column content">
  <br />
<h3>Notes</h3>
<table class="footnote">
  <tr>

    <td class="number">1</td>

    <td class="reference"><a name="fn1"></a>“Voice Interfaces”, <em> Infosys </em>, 2019, accessed 3 November 2021<ahref="https://www.infosys.com/services/incubating-emerging-technologies/offerings/Documents/voice-interfaces.pdf."target="_blank">https://www.infosys.com/services/incubating-emerging-technologies/offerings/Documents/voice-interfaces.pdf.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref1">&uarr;</a></span></td>
        	</tr>

        	<tr>
        	<td class="number">2</td>

        	<td class="reference"><a name="fn2"></a>Rudnicky, A. I., “The Design of Voice-driven Interfaces”, In <em>Proceedings of the Workshop on Speech and Natural Language, </em>(Association for Computational Linguistics, USA, 1989), 120–124.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref2">&uarr;</a></span></td>
        	</tr>

      	<tr>
        	<td class="number">3</td>
  	<td class="reference"><a name="fn3"></a>Rudnicky, A. I., <em> “The Design of Voice-driven Interfaces”, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref3">&uarr;</a></span></td>

        	</tr>

  	<tr>
  <td class="number">4</td>
  <td class="reference"><a name="fn4"></a>Cole, R., et al., “The Challenge of Spoken Language Systems: Research Directions for the Nineties”, <em>IEEE Transactions on Speech and Audio Processing, </em> 3, no. 1 (1995): 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref4">&uarr;</a></span></td>
  	</tr>

               <tr>
  <td class="number">5</td>
    <td class="reference"><a name="fn5"></a>Ayesha Pervaiz, et al., “Incorporating Noise Robustness in Speech Command Recognition by Noise Augmentation of Training Data”, <em> Sensors 20 </em>, no. 8 (2020): 2336–2337,<ahref="https://doi.org/10.3390/s20082326."target="_blank">https://doi.org/10.3390/s20082326.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref5">&uarr;</a></span></td>

  	</tr>
        	<tr>
  <td class="number">6</td>
  <td class="reference"><a name="fn6"></a>Cole, R., et al., “The Challenge of Spoken Language Systems: Research Directions for the Nineties”, <em>IEEE Transactions on Speech and Audio Processing, </em> 3, no. 1 (1995): 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref6">&uarr;</a></span></td>
  	</tr>
        	<tr>
        	<td class="number">7</td>
        	<td class="reference"><a name="fn7"></a>Cole, R., et al., “The Challenge of Spoken Language Systems: Research Directions for the Nineties”, <em>IEEE Transactions on Speech and Audio Processing, </em> 3, no. 1 (1995): 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref7">&uarr;</a></span></td>

  	</tr>
        	<tr>
        	<td class="number">8</td>
        		<td class="reference"><a name="fn8"></a>Rudnicky, A. I., <em> “The Design of Voice-driven Interfaces”, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref8">&uarr;</a></span></td>

        	</tr>
               <tr>
    	<td class="number">9</td>
  <td class="reference"><a name="fn9"></a>Dyches, H., Alemagno, S., Llorens, S. A., and Butts, J. M., “Automated Telephone-Administered Substance Abuse Screening for Adults in Primary Care”, <em>Health Care Management Science, </em> 2, no. 4 (1999): 199–204 <a href="doi:10.1023/a:1019000231214." target="_blank">doi:10.1023/a:1019000231214.  </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref9">&uarr;</a></span></td>

      	</tr>
          	<tr>
  	<td class="number">10</td>
  <td class="reference"><a name="fn10"></a>“Usage Statistics of Content Languages for Websites”, <em> W3Techs, </em> accessed 3 November 2021 <a href="https://w3techs.com/technologies/overview/content_language."target="_blank">https://w3techs.com/technologies/overview/content_language.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref10">&uarr;</a></span></td>
  	</tr>
                <tr>
        	<td class="number">11</td>
        	<td class="reference"><a name="fn11"></a>Noack, R., “The Future of Language”, <em> Washington Post, </em> September 25,2015,<a href="https://www.washingtonpost.com/news/worldviews/wp/2015/09/24/the-future-of-language/."target="_blank">https://www.washingtonpost.com/news/worldviews/wp/2015/09/24/the-future-of-language/."</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref11">&uarr;</a></span></td>

        	</tr>
        	<tr>
        	<td class="number">12</td>

     <td class="reference"><a name="fn12"></a>The terms ‘native language’ and ‘native speaker’ are used here in the specific context of the report cited. As socio-cultural constructs, the terms have been a source of debate, particularly in postcolonial contexts and in the field of linguistics, and more recently in efforts related to language revitalisation. For more on this see: Davies, Alan. The Native Speaker: Myth and Reality. Multilingual Matters, 2003 and  O’Rourke, Bernadette. “New Speakers of Minority Languages.” <em>The Routledge Handbook of Language Revitalization,</em> 2018, 265–73.<a href=" https://doi.org/10.4324/9781315561271-33."target="_blank">https://doi.org/10.4324/9781315561271-33.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref12">&uarr;</a></span></td>


        	</tr>
        	<tr>
        	<td class="number">13</td>
  	<td class="reference"><a name="fn13"></a>Noack, R., “The Future of Language ”, <em> Washington Post. </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref13">&uarr;</a></span></td>
        	</tr>
              <tr>
  <td class="number">14</td>
  <td class="reference"><a name="fn14"></a>Noack, R., “Usage Statistics of Content Languages for Websites”, <em> W3Techs, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref14">&uarr;</a></span></td>


  	</tr>
    <tr>
  <td class="number">15</td>
  <td class="reference"><a name="fn15"></a>Cole,“The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref15">&uarr;</a></span></td>
        </tr>
              <tr>
  <td class="number">16</td>
        	<td class="reference"><a name="fn16"></a>Cole,“The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref16">&uarr;</a></span></td>

        	</tr>
  <tr>
        	<td class="number">17</td>
<td class="reference"><a name="fn17"></a>Freitas, J., et al., “Spoken Language Interface for Mobile Devices”,  in Human Language Technology. Challenges of the Information Society, </em> eds. Zygmunt Vetulani, Hans Uszkoreit (Springer, Berlin, Heidelberg, 2009), 25–35. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref17">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">18</td>
  <td class="reference"><a name="fn18"></a>“RecognizedPhrase.Confidence Property”, Microsoft, accessed 17 November 2021,<a href=" https://docs.microsoft.com/en-us/dotnet/api/system.speech.recognition.recognizedphrase.confidence?view=netframework-4.8.target="_blank”>https://docs.microsoft.com/en-us/dotnet/api/system.speech.recognition.recognizedphrase.confidence?view=netframework-4.8.</a>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref18">&uarr;</a></span></td>
        	</tr>
  <tr>
            	<td class="number">19</td>
              	<td class="reference"><a name="fn19"></a>Cole, “The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref19">&uarr;</a></span></td>
        	</tr>
        	<tr>
        	<td class="number">20</td>
  	<td class="reference"><a name="fn20"></a>Cole, “The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref20">&uarr;</a></span></td>
        	</tr>

      	<tr>
        	<td class="number">21</td>
  <td class="reference"><a name="fn21"></a>The Information Technology Act, 2000.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref21">&uarr;</a></span></td>

        	</tr>
  	<tr>
  <td class="number">22</td>
  <td class="reference"><a name="fn22"></a>Hernandez, Daniela, “How Voice Recognition Systems Discriminate Against People with Accents: When Will There be Speech Recognition for the Rest of Us?”, <em> Splinter </em> , 21 August 2015,<a href="https://splinternews.com/how-voice-recognition-systems-discriminate-against-peop-1793850122."target="_blank">https://splinternews.com/how-voice-recognition-systems-discriminate-against-peop-1793850122.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref22">&uarr;</a></span></td>
  	</tr>
               <tr>
  <td class="number">23</td>
  <td class="reference"><a name="fn23"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref23">&uarr;</a></span></td>
  	</tr>
        	<tr>
  <td class="number">24</td>
  <td class="reference"><a name="fn24"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref24">&uarr;</a></span></td>
  	</tr>
        	<tr>
  <td class="number">25</td>
        	<td class="reference"><a name="fn25"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref25">&uarr;</a></span></td>
        	</tr>
        	<tr>
        	<td class="number">26</td>
        	<td class="reference"><a name="fn26"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref26">&uarr;</a></span></td>

        	</tr>
               <tr>
    	<td class="number">27</td>
  <td class="reference"><a name="fn27"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref27">&uarr;</a></span></td>
      	</tr>
          	<tr>
  	<td class="number">28</td>
  <td class="reference"><a name="fn28"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref28">&uarr;</a></span></td>
  	</tr>
                <tr>
        	<td class="number">29</td>
        	<td class="reference"><a name="fn29"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref29">&uarr;</a></span></td>
     	</tr>
        	<tr>
        	<td class="number">30</td>
  <td class="reference"><a name="fn30"></a>Walkley, A. and Nagpal, J. “Why Hindi Matters in the Digital Age”,  <em> Think with Google, </em> 2015, from<ahref=”https://www.thinkwithgoogle.com/intl/en-apac/trends-and-insights/hindi-matters-digital-age/.”target="_blank”>https://www.thinkwithgoogle.com/intl/en-apac/trends-and-insights/hindi-matters-digital-age/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</a></span></td>
        	      	<tr>
        	<td class="number">31</td>
  <td class="reference"><a name="fn31"></a>Sanchez-Stockhammer, Christina, “Hybridization in Language”, In <em> Conceptualizing Cultural Hybridization: A Transdisciplinary Approach, </em> ed. Philipp Wolfgang Stockhammer, (Springer-Verlag Berlin Heidelberg, 2012), 133-157.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</a></span></td>
        	</tr>
              <tr>
  <td class="number">32</td>
  <td class="reference"><a name="fn32"></a>Baker, S., “Will We all be Speaking Hinglish One Day?”, <em> British Council, </em> 2015, accessed 3 November 2021 <ahref=”https://www.britishcouncil.org/voices-magazine/will-we-all-be-speaking-hinglish-one-day”target="_blank”>https://www.britishcouncil.org/voices-magazine/will-we-all-be-speaking-hinglish-one-day</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref32">&uarr;</a></span></td>

  	</tr>
              <tr>
  <td class="number">33</td>

  	<td class="reference"><a name="fn33"></a>Lawrence, “Beyond the Graphic User Interface”.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</a></span></td>

        </tr>
              <tr>
  <td class="number">34</td>
        	<td class="reference"><a name="fn34"></a>Skiba, R., “Code switching as a Countenance of Language Interference”, <em> The Internet TESL Journal, </em> 3, no. 10 (1997): 1–6.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">35</td>
  <td class="reference"><a name="fn35"></a>Crystal, D. The Cambridge <em> Encyclopedia of Language, </em> (Cambridge University Press, 1987), 372-375.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref35">&uarr;</a></span></td>
         	</tr>
  <tr>
        	<td class="number">36</td>
  <td class="reference"><a name="fn36"></a>“The Challenge of Spoken Language”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref36">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">37</td>
  <td class="reference"><a name="fn37"></a>Martin, R., “Common Voice Languages and Accent Strategy v5”, <em> Mozilla, </em> 2020, accessed 3 November 2021,<ahref=”https://discourse.mozilla.org/t/common-voice-languages-and-accent-strategy-v5/56555”target="_blank”>,https://discourse.mozilla.org/t/common-voice-languages-and-accent-strategy-v5/56555</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref37">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">38</td>
  <td class="reference"><a name="fn38"></a>McEvoy, J., “A Few Differences Between French Spoken in Québec and France”, <em> British Council, </em> 2017, accessed 3 November 2021<ahref=”https://www.britishcouncil.org/voices-magazine/few-differences-between-french-spoken-quebec-and-france target="_blank”>https://www.britishcouncil.org/voices-magazine/few-differences-between-french-spoken-quebec-and-france</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref38">&uarr;</a></span></td>
        	</tr>
  </tr>
  <tr>
        	<td class="number">39</td>
  <td class="reference"><a name="fn39"></a>“Why Common Voice?”, <em> Common Voice, </em> <ahref=”https://commonvoice.mozilla.org/en/about”target="_blank”>https://commonvoice.mozilla.org/en/about</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref39">&uarr;</a></span></td>

        	</tr>
  <tr>
        	<td class="number">40</td>
  <td class="reference"><a name="fn40"></a>“Why Common Voice?”, <em> Common Voice. </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref40">&uarr;</a></span></td>

        	</tr>
  <tr>
        	<td class="number">41</td>
  <td class="reference"><a name="fn41"></a>Martin, R., “Common Voice Languages and Accent Strategy v5”, <em> Mozilla </em>. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref41">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">42</td>
  <td class="reference"><a name="fn42"></a>Paul, S. “Voice Is the Next Big Platform, Unless You Have an Accent”, <em> Wired, </em> 2017,<ahref=”https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/”target="_blank”>https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref42">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">43</td>
  <td class="reference"><a name="fn43"></a>Paul, S. “Voice Is the Next Big Platform, Unless You Have an Accent”, <em> Wired, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref43">&uarr;</a></span></td>

        	</tr>


  <tr>
        	<td class="number">44</td>
  <td class="reference"><a name="fn44"></a>Ali,“Why Common Voice?”, <em> Common Voice. </em> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref44">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">45</td>
  <td class="reference"><a name="fn45"></a>Ali,“Why Common Voice?”, <em> Common Voice. </em> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref45">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">46</td>
  <td class="reference"><a name="fn46"></a>Branson, M., “Help Create Common Voice’s First Target Segment”, <em> Mozilla, </em> 2020, accessed 3 November 2020<ahref=”https://discourse.mozilla.org/t/help-create-common-voices-first-target-segment/59587”target="_blank”>.https://discourse.mozilla.org/t/help-create-common-voices-first-target-segment/59587</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref46">&uarr;</a></span></td>
  	</tr>
  	</tr>
  <tr>
        	<td class="number">47</td>
  <td class="reference"><a name="fn47"></a>Branson, M., “More Data, More Languages, and Introducing our First Target Segment!”, <em> Mozilla </em>, 2020, accessed 3 November 2021 <ahref=”https://discourse.mozilla.org/t/common-voice-dataset-release-mid-year-2020/62938”target="_blank”>https://discourse.mozilla.org/t/common-voice-dataset-release-mid-year-2020/62938</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref47">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">48</td>
  <td class="reference"><a name="fn48"></a>“Mission”, <em> Linguistic Data Consortium, </em>accessed 3 November 2021,<ahref=”https://www.ldc.upenn.edu/about/mission”target="_blank”> https://www.ldc.upenn.edu/about/mission</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref48">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">49</td>
  <td class="reference"><a name="fn49"></a>“About LDC”, <em> Linguistic Data Consortium, </em>accessed 3 November 2021,<ahref=”https://www.ldc.upenn.edu/about/”target="_blank”> https://www.ldc.upenn.edu/about/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref49">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">50</td>
  <td class="reference"><a name="fn50"></a>“Other Collaborations” <em> Linguistic Data Consortium, </em>accessed 3 November 2021,<ahref=”https://www.ldc.upenn.edu//collaborations/other”target="_blank”> https://www.ldc.upenn.edu/collaborations/other</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref50">&uarr;</a></span></td>
  	</tr>

  <tr>
        	<td class="number">51</td>
  <td class="reference"><a name="fn51"></a>“Tagset for Indian Languages”, <em> Sketch Engine, </em> accessed 3November2021<ahref=”https://www.sketchengine.eu/tagset-indian-languages/”target="_blank”>https://www.sketchengine.eu/tagset-indian-languages/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref51">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">52</td>
  <td class="reference"><a name="fn52"></a>“VoxForge”, <em> VoxForge, </em><ahref=”http://www.voxforge.org/.”target="_blank”>http://www.voxforge.org/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref52">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">53</td>
  <td class="reference"><a name="fn53"></a>“The M-AILABS Speech Dataset”, <em> Caito,</em> accessed 3 November 2021<ahref=”https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/.“target="_blank”>https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref53">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">54</td>
  <td class="reference"><a name="fn54"></a>“About Us”, <em> National Platform for Language Technology </em> <ahref=”https://nplt.in/demo/about-nplt,”target="_blank”>https://nplt.in/demo/about-nplt,</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref54">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">55</td>
  <td class="reference"><a name="fn55"></a>“Voices”, <em> Indic TTS </em> <ahref=” https://www.iitm.ac.in/donlab/tts/voices.php“target="_blank”>https://www.iitm.ac.in/donlab/tts/voices.php</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref55">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">56</td>
  <td class="reference"><a name="fn56"></a>“Android Applications”, <em> Indic TTS </em> <ahref=”https://www.iitm.ac.in/donlab/tts/androidapp.php”target="_blank”>https://www.iitm.ac.in/donlab/tts/androidapp.php </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref56">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">57</td>
  <td class="reference"><a name="fn57"></a>”Lawrence, “Beyond the Graphic User Interface”.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref57">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">58</td>
  <td class="reference"><a name="fn58"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref58">&uarr;</a></span></td>



</tr>
</table>
    </div>
  </div>

      <div class="six wide column empty">
      </div>


    </div>
  </div>
  <!-- Footer -->
  <div class="footer">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="five wide column">
        <h3>About the Study</h3>
        <p>We believe that voice interfaces have the potential to democratise the use of the internet by addressing limitations related to reading and writing on digital text-only platforms and devices. This report examines the current landscape of voice interfaces in India, with a focus on concerns related to privacy and data protection, linguistic barriers, and accessibility for persons with disabilities (PwDs). This project was undertaken with support by the Mozilla Corporation.</p>
      </div>
      <div class="five wide column">
        <h3>Research Team</h3>
        <p>Research: Shweta Mohandas, Saumyaa Naidu, Deepika NS, Divya Pinheiro, Sweta Bisht </p>
        <p><em>Conceptualisation, Planning, and Research Inputs</em> Sumandro Chattapadhyay, Puthiya Purayil Sneha</p>
        <p><em>Illustration</em> Kruthika NS</p>
        <p><em>Website Design</em> Saumyaa Naidu</p>
        <p><em>Website Development</em> Sumandro Chattapadhyay, Pranav M Bidare</p>
        <p><em>Review and Editing</em> Puthiya Purayil Sneha, Divyank Katira, Pranav M Bidare, Torsha Sarkar, Pallavi Bedi, Divya Pinheiro</p>
        <p><em>Copy Editing</em> The Clean Copy</p>
      </div>
      <div class="four wide column">
        <h3>Copyright and Credits</h3>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2021<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a><br/><a href="https://fonts.google.com/specimen/Barlow" target="_blank">Barlow</a> and <a href="https://fonts.google.com/specimen/Open+Sans" target="_blank">Open Sans</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/cis-india/mozvoice" target="_blank">GitHub</a></p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="sixteen wide column">
        <div style="float: center; clear: both;">
        <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons" style="float: center; clear: both;">
          <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
	</div>
      </div>
    </div>
  </div>
</body>
</html>
