<!DOCTYPE html>
<html><!DOCTYPE html>
<html>
<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Making Voices Heard | A study by the Centre for Internet and Society, India, supported by Mozilla Corporation" />
  <!-- Title + CSS + Favicon -->
  <title>Making Voices Heard</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Header -->
  <div>
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <!-- Top Navigation Bar -->
  <div class="blue nav">
    <div class="ui container">
      <div class="nav-entries">
        <a href="index.html" id="home">Home</a> <a href="design-brief.html">Design Brief</a> <span id="inactive">Policy Brief</span> <a href="mapping-actors.html">Mapping Actors</a> <a href="#case-studies">Case Studies</a> <a href="#literature-surveys">Literature Surveys</a> <a href="#resources">Resources</a> <span id="report"><a href="docs/CIS_MakingVoicesHeard_Report.pdf"><i class="fas fa-arrow-circle-down"></i> Get Full Report</a></span>
      </div>
    </div>
  </div>
  <!-- Title -->
  <div class="grey">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column text">
        <h2>Voice Interfaces and Language</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="nine wide column text">

        <h3 id="about">Background</h3>
        <p> If we take voice interfaces(VIs) to be machines, then language is both the raw material and the final product – speech data is fed into these systems to train them, based on which they convert text to speech or vice versa. Hence, the key feature of VIs is the ability to convert human language into machine-readable language and vice versa. The four most significant technologies for enabling VIs, as listed by an Infosys Report in 2019, are text to speech (TTS), automatic speech recognition, natural language understanding (NLU), and natural language generation. <sup class="superscript"><a href="#fn1">1</a></sup><a name="ref1"></a>Apart from these technologies, Rudnicky enumerated the following factors needed to design a VI:   <sup class="superscript"><a href="#fn2">2</a></sup><a name="ref2"></a>
        <ul>
           <li><p><b>Language design:</b> Refers to creating a ‘habitable’ language to enable the machine to “capture the range of expression”<sup class="superscript"><a href="#fn3">3</a></sup><a name="ref3"></a> of the individual, thereby creating a suitable spoken language from human–machine interaction.</li></p>
<p> </p>
           <li><p><b>Fluent interaction:</b> The process by which the  individual deems the machine utilising VIs to be a competent interlocutor.</li></p>
<p> </p>
           <li><p><b>Recognition:</b> Speech recognition in VIs requires ‘robustness’.<sup class="superscript"><a href="#fn4">4</a></sup><a name="ref4"></a> A robust VI is characterised by having standardised models to recognise speech efficiently.<sup class="superscript"><a href="#fn5">5</a></sup><a name="ref5"></a></li></p>
<p> </p>
        </ul>
        </p>
<p> Without this characteristic, the interface would be subject to systemic fluctuations in acoustic signals.<sup class="superscript"><a href="#fn6">6</a></sup><a name="ref6"></a> This would lead to modifications in input conditions which would minimally degrade the performance of the interface.<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> Building standardised models, thereby, would enable individuals  to interact with VIs with high accuracy levels.<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a></p>
<h4>Significant challenges for multilingual support</h4>
<p> In an empirical study conducted by Dyches et al ,<sup class="superscript"><a href="#fn9">9</a></sup><a name="ref9"></a> 724 participants in Ohio were approached to assess the current state of the interactive voice response (IVR) system for non acute primary care. However, only 42% of the participants were able to finish the telephone screening. The rest were not able to complete the IVR process in the research for several reasons. One of the most significant reasons cited was not knowing English. Hence, developing a VI in all local, regional languages would be a step towards making digital spaces truly democratic.</p>
<p> This idea, however, has not come to fruition because of the challenge involved in developing VIs in local languages. The major challenge is  further reflected in a W3Tech survey, as depicted in Graph 1, which reveals that English was used by 59.5% of approximately 10 million global websites as of June 2020.<sup class="superscript"><a href="#fn10">10</a></sup><a name="ref10"></a> The websites surveyed by W3Tech, however, include only websites that use technology and have “useful content”. To elaborate further, default web server pages and websites owned by domain spammers were excluded from the survey. In addition, subdomains and redirected domains were not included in the survey.</p>
<p>The aforementioned statistics become even more significant when we consider global demographics – only 527 million people in the world, out of approximately 7.2 billion, are native English speaking people.<sup class="superscript"><a href="#fn11">11</a></sup><a name="ref11"></a> The population of native speakers<sup class="superscript"><a href="#fn12">12</a></sup><a name="ref12"></a> of three languages, namely, all Chinese dialects combined, Hindi, and Urdu is higher than the native English speaking population.<sup class="superscript"><a href="#fn13">13</a></sup><a name="ref13"></a> However, the use of these languages in website content in the two most populous countries namely China and India, are minuscule in terms of percentage. For China, it stands at 1.50%, while Hindi is behind at 0.1%. However, less than 0.1% of the 10 million (approximate value) websites surveyed accounted for using Indic languages such as Bengali, Kannada, Tamil, Telugu, Marathi, Punjabi, Gujarati, Oriya Urdu, and Assamese.<sup class="superscript"><a href="#fn14">14</a></sup><a name="ref14"></a></p>
<p>Ultimately, to address language-related challenges, building an efficient VI equipped with multilingual support is the need of the hour. This requires the expertise of computational linguists to create the domain model –i.e., build the lexicon for NLU systems and fine-tune and debug the grammar for the same.<sup class="superscript"><a href="#fn15">15</a></sup><a name="ref15"></a> Another main challenge is that it remains an expensive procedure as it requires the labour of individuals with a very niche skill set.<sup class="superscript"><a href="#fn16">16</a></sup><a name="ref16"></a> Similarly, Levinson (1994) opines that the language accessibility barriers of VIs are predominantly compounded by the lack of technical expertise to create such devices. Though the recent trend of consumer facing VIs show that there is no dearth of technical expertise, the particular nature of voice and languages still create technological challenges.</p>
<p>To summarise, the reluctance to develop VIs in several languages is primarily linked to the low scope for profitability and the labour-intensive requirement of computational linguists. In addition to these factors, several additional impediments have been identified for the development of interfaces in (non-dominant) local languages:</p>
<ol>
   <li><p><b>Inaccuracy</b> A major impediment is systemic fluctuations, which result in inaccurate speech recognition vis-a-vis natural language.<sup class="superscript"><a href="#fn17">17</a></sup><a name="ref17"></a> However, inaccuracy can be reduced by improving the interface’s capability to gauge speech input with ‘confidence’. A VI is deemed to be confident if it has the ability to accurately recognise even the unusual input that it receives.<sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a> This is predominantly in the form of words beyond the vocabulary of the interface, or different individuals interacting with the same interface, or usage of different microphones, or background noise.<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a> Cole et al. opine that if a VI lacks confidence, they “produce unacceptable errors, and are unable to engage the speaker in graceful dialogues”.<sup class="superscript"><a href="#fn20">20</a></sup><a name="ref20"></a> This also leads to  individuals becoming frustrated with their devices due to multiple inaccurate speech interactions.<sup class="superscript"><a href="#fn21">21</a></sup><a name="ref21"></a>
</li></p>

<p> </p>
   <li><p><b>Foreign accents</b> Inaccuracy is a challenge for the adoption of VIs, especially among non-English speaking  individuals.<sup class="superscript"><a href="#fn22">22</a></sup><a name="ref22"></a> Similarly, all English speakers without an American accent tend to have significantly less accurate interactions with VIs.<sup class="superscript"><a href="#fn23">23</a></sup><a name="ref23"></a> According to Hernandez, the error rate of VIs for American English voice interactions is 8%, with most of the words that were incorrectly identified being unique proper nouns or location names.<sup class="superscript"><a href="#fn24">24</a></sup><a name="ref24"></a> However, with Spanish and British English, the error rate was 10%.<sup class="superscript"><a href="#fn25">25</a></sup><a name="ref25"></a> The highest error rate, at 20% or above, was for the neglected ‘Tier 2 languages’ (languages that were not as popular with tech companies).<sup class="superscript"><a href="#fn26">26</a></sup><a name="ref26"></a> To put things in perspective, this implies that the device, on average, could not identify one out of five words spoken in a specific English accent.<sup class="superscript"><a href="#fn27">27</a></sup><a name="ref27"></a>
 <p> Like in the case of multilingual support, accent incorporation is an expensive endeavour with low chances of profitability.<sup class="superscript"><a href="#fn28">28</a></sup><a name="ref28"></a> Hence, an approach must be devised to move beyond market-driven forces to acknowledge the potential that VIs have to radically transform lives. As Lawrence rightly asserts, “as the market for speech technologies expands, the user base becomes more heterogeneous, and understanding new audiences with differing abilities, attitudes, and language backgrounds is paramount”.<sup class="superscript"><a href="#fn29">29</a></sup><a name="ref29"></a></p>
<p>In India, the incorporation of Indian regional languages into VIs remains a very resource-intensive task, owing to the linguistic diversity of the country.<sup class="superscript"><a href="#fn30">30</a></sup><a name="ref30"></a> Further, diverse languages have led to the emergence of different accents. Hence, this is something to be considered while using the umbrella term ‘Indian accent’. Therefore, another impediment to VI adoption is the complexity involved in speech recognition for Indian accents.</p>
<p><strong>Table 2 </strong>depicts the number of Indian regional languages and the ‘Indian accent’ supported by several voice-enabled devices. Out of the seven devices, only two supported at least one Indian language, but all seven were available in English.</p>
</li></p>
<p> </p>
   <li><p><b>Hybridism of English</b> Globalisation, transnationality, and cultural exchanges have led to the hybridism of English.<sup class="superscript"><a href="#fn31">31</a></sup><a name="ref31"></a> The most popular form in India is ‘Hinglish’, which is a hybrid of Hindi and English.<sup class="superscript"><a href="#fn32">32</a></sup><a name="ref32"></a> With the English language becoming the world’s lingua franca, hybridism is a global phenomenon. However, despite the surge in ‘Spanglish’, ‘Chinglish’, and ‘Manglish’ as well as several other English hybrid forms, little to no progress has been made in developing VIs for individuals speaking in these languages.<sup class="superscript"><a href="#fn33">33</a></sup><a name="ref33"></a></li></p>
   <li><p><b>Code-switching </b> Code-switching is defined as speech that comprises more than one language, which is more common in multilingual communities.<sup class="superscript"><a href="#fn34">34</a></sup><a name="ref34"></a> In India, English words are often mixed into sentences in Indian languages. Researchers have found possible reasons for code-switching, such as the speaker not being able to express themselves fully in one language and switching to the other to compensate for the deficiency. Switching can also occur when an individual wishes to express solidarity with a particular social group or when the speaker tries to include people in a conversation who do not speak one of the languages.<sup class="superscript"><a href="#fn35">35</a></sup><a name="ref35"></a> In VIs and the automated processing of spoken communications, code switching presents an issue of understanding context and knowing that the added word is from a different language.</li></p>
<li><p><b>Coarticulation variability </b> An imperative research challenge for VIs in a linguistic context, as observed by Cole et al. (1995), is “coarticulation variability.”<sup class="superscript"><a href="#fn36">36</a></sup><a name="ref36"></a> The term refers to the inherent linguistic subjectivity of a sound segment due to factors such as accent, idiolect, and sociolect. <sup class="superscript"><a href="#fn37">37</a></sup><a name="ref37"></a> For instance, linguistic subjectivity can be observed with French, as the same language varies tremendously when spoken in France and Canada.<sup class="superscript"><a href="#fn38">38</a></sup><a name="ref38"></a></p>
<p>In the Mozilla Common Voice project, the collection of voice data segments for machine learning is a two-pronged process involving contributors recording voice clips and the verification of the accuracy of the same recording.<sup class="superscript"><a href="#fn39">39</a></sup><a name="ref39"></a> If two  individuals vote that the voice recording provided is accurate, it will enter the Common Voice dataset; however, if two individuals do not approve of the recording, it will enter what Common Voice terms as the ‘Clip Graveyard’.<sup class="superscript"><a href="#fn40">40</a></sup><a name="ref40"></a> However, this process can be biased due to coarticulation variability – a voice recording might get sent to the Clip Graveyard if the articulation of words, despite being accurate, does not match the pronunciation of the individual verifying the recording. However, Common Voice has explicitly acknowledged this limitation vis-a-vis their voice corpus.<sup class="superscript"><a href="#fn41">41</a></sup><a name="ref41"></a></p>
<p> </p>
</ul>
</p>

    <h3 id="methodology">Voice initiatives to bridge the digital divide</h3>

    <h4>Language and text selection</h4>
        <p> The process of creating voice datasets in Indian languages involved several steps, beginning with the selection of languages that are the focus of the project and then building speech technologies using the voice datasets. The selection of the 13 languages was based on the following criteria: optimal text selection, speaker selection, pronunciation variation, recording specification, text correction for handling out-of-the-vocabulary words, and data verification.<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> To ensure the quality of data, characteristics that affect speech synthesis quality such as encoding (converting one form of data to another), sampling rate (number of samples of audio recorded every second) etc. were considered. The sentences for the speech recordings were taken through web crawlers from newspaper reports, Wikipedia pages, websites, and blogs in the respective Indian language. To achieve good coverage of topics and words, sentences were also taken from different types of literature, including children’s stories, science writing, tourism content, etc. Care was also taken to ensure that the texts were commonly used, free of errors, easy to read, and covered a wide range of words and syllables. Code-mixed sentences were avoided.</p>
        <h4>Speaker selection and recording </h4>
        <p> To create speech recordings for the datasets, two voice talents – a male and a female – were chosen for each language. The recordings were made in a studio room without noise or echo for clarity of the recordings. The voice talents were voice professionals who were either voice artists or newsreaders to ensure clarity in the pronunciation and diction. They were given breaks every 45 minutes to avoid fatigue. In each recording, individual sentences were isolated. A total of 40 hours of speech data was collected for a given language – 20 hours of Indian monolingual/single language data (10 hours each of male and female voice data) and 20 hours of English data recorded by first language speakers (10 hours each of male and female voice data). The recorded files were stored in .wav format to ensure that the recordings were of high sound quality.</p>
      <h4>Text-to-speech synthesis</h4>
        <p>One of the researchers in the Indic TTS project defines text-to-speech synthesis as the “process of converting an arbitrary input text to its corresponding speech output”. In the context of Indian languages, the TTS system uses syllables or phonemes (units of sound that can distinguish one word from another in a particular language) as a sub-word unit (where words are split into smaller words that occur more frequently). The three major components involved in building a TTS system are text parsing, speech segmentation, and speech modelling.<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a> Simply put, the objective of a TTS system is to convert text into speech output. TTS systems can be divided into two types – domain-specific and vocabulary independent. In the case of domain specific systems, the words/text to be synthesised should be limited to a particular domain, such as banking or railway broadcast, while for vocabulary independent systems, any text will work. </p>
          <h3 id="languages">Languages</h3>
        <p>The main motivation for the project was to address the unavailability of voice data in Indian languages. The functioning of a TTS system is dependent on the training data that is fed into the system, which includes speech .wav files along with a transcript of the corresponding text. The TTS project aims to develop text-to-speech synthesisers for 13 Indian languages, which could help researchers and developers work on Indian voice applications. One of the goals of the project is to make the voice of the text-to-speech system sound as natural and understandable as possible. The first phase of the project concentrated on three languages (3 Indo-Aryan languages and 3 Dravidian languages), the second phase added 7 more languages to the study.</p>
        <h3 id="access">Access and accessibility</h3>
        <p>The TTS project was started with the idea of giving people with disabilities access to regional information on the internet, such as news reports in Indian languages. Since the consortium is a publicly funded project, the datasets and research have been made public on its website. The datasets are available free of cost to researchers – they just need to log in to the website to use them. Start-ups and businesses that want to use the data can sign a Memorandum Of Understanding with Indic TTS and access the data.</p>

      <h3 id="privacy">Privacy and data collection</h3>
        <p>As stated earlier, the text data for training the systems was taken from publicly available sources such as online news portals, Wikipedia pages, websites, and blogs; hence, privacy and data protection are not significant concerns. Additionally, with regard to the speech data, the readings were done by professional voice artists who recorded sounds and words for the project based on a script provided to them by the researchers.</p>

     <h3 id="challenges">Challenges</h3>

        <p>One of the main challenges for the researchers was ensuring that the datasets were comprehensive and accurate while keeping the cost of creating and accessing them low. Since the project was publicly funded, the researchers needed to work with the available funding and ensure that the research was accessible and free. As stated earlier, the data and the research are open to researchers,  and start-ups can request the data after signing an MOU. Another challenge was making the speech output sound more human-like and less robotic, similar to the heavily funded and data-rich interfaces of Amazon and Google. The other challenge was making the output speech systems context-specific, such as with children’s books.
        Voice interfaces provide accessibility support for individuals who are unable to see the screen or understand the text. However, no applications other than Google and Amazon claim to provide accessibility features. Amazon Echo’s website lists the various features that customers with vision, hearing, mobility, and speech accessibility needs could use. <sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a> Google Home provides accessibility features that allow the individual to control appliances and entertainment, make phone calls, broadcast messages, and manage tasks in addition to its voice assistant.<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a></p>

      <h3 id="future">Future of Indic TTS</h3>
        <p>The project looks at continuing research and data collection with the help of government funding. Given the scale and amount of funding needed for such projects, including the requirement of infrastructure and trained human resources, the government is the primary source of funding. With the new funding from the Ministry of Electronics and Information Technology, the researchers at IITM have started a project to make English lecture videos available in Indian languages. The objective of this project is to make lectures in different domains, like humanities, healthcare, etc., freely accessible to students in their languages. This is a small-scale project, and Indic TTS hopes to expand it to more languages and subjects. </p>
        <br />
    <i> Disclaimer: This is an independent case study conducted as a part of the Making Voices Heard Project, supported by the Mozilla Corporation. The researchers have not received any external remuneration as a part of this case study, and claim no conflict of interest.</i>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="five wide column meta">
        <p><span id="grey">Research and Writing by</span> <br />Shweta Mohandas and Saumyaa Naidu
          <br />
        <span id="grey">Review and Editing by</span> <br />Puthiya Purayil Sneha, <br /><span id="grey">and</span> Torsha Sarkar<br />
        <span id="grey">Research Inputs by</span> <br />Sumandro Chattapadhyay<br />
	       <br />
        <a href="docs/MozVoice_PolicyBrief_02.pdf"><i class="fas fa-arrow-circle-down" style="color: black;" ></i> Download Policy Brief</a></p>
        <br />
         <hr />
	       <br />
        <p><span style="line-height: 3em;">CONTENTS</span></p>
	      <p><a href="#about"><strong>About</strong></a></p>
        <p><a href="#methodology"><strong>Methodology and Process</strong></a></p>
        <p><a href="#languages"><strong>Languages</strong></a></p>
        <p><a href="#access"><strong>Access and accessibility</strong></a></p>
        <p><a href="#privacy"><strong>Privacy and data collection </strong></a></p>
        <p><a href="#challenges"><strong>Challenges</strong></a></p>
        <p><a href="#future"><strong>Future of Indic TTS</strong></a></p>
</div>

<div class="ten wide column content">
</div>
<div class="ten wide column content">
  <br />
<h3>Notes</h3>
<table class="footnote">
  <tr>
    <td class="number">1</td>
<td class="reference"><a name="fn1"></a> Baby, Arun et al., "Resources for Indian Languages", In <em>Proceedings of CBBLR workshop, International Conference on Text, Speech and Dialogue</em>. Springer, 2016.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref1">&uarr;</a></span></td>

      	</tr>

<tr>
        	<td class="number">2</td>
      	<td class="reference"><a name="fn2"></a>“Indic TTS”, Indic TTS;Department of Electronics and Information Technology (DEITY) has been renamed to Ministry of Electronics and Information Technology (MEITY) 03 November 2021, <a href="https://www.iitm.ac.in/donlab/tts/ " target="_blank"> https://www.iitm.ac.in/donlab/tts/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref2">&uarr;</a></span></td>
      	</tr>


<tr>
        	<td class="number">3</td>
    <td class="reference"><a name="fn3"></a> “Indic TTS”,<em> Indic TTS.</em> Accessed 3 November 2021. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref3">&uarr;</a></span></td

      	</tr>


<tr>
        	<td class="number">4</td>
    <td class="reference"><a name="fn4"></a>Baby Arun, "Resources for Indian Languages"&nbsp;&nbsp;<span class="internal-nav"><a href="#ref4">&uarr;</a></span></td

      	</tr>
<tr>
        	<td class="number">5</td>

<td class="reference"><a name="fn5"></a> “An Introduction to Optical Character Recognition for Beginners”, Towards Data Science, accessed 5 January 2022, <a href="https://towardsdatascience.com/an-introduction-to-optical-character-recognition-for-beginners-14268c99d60"target="_blank">https://towardsdatascience.com/an-introduction-to-optical-character-recognition-for-beginners-14268c99d60 </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref5">&uarr;</a></span></td>

      	</tr>

<tr>
        	<td class="number">6</td>

<td class="reference"><a name="fn6"></a> Tan,Zhixing et al., “Neural machine translation: A review of methods, resources, and tools”, AI Open Volume 1.(2020):5-21, <a href="https://doi.org/10.1016/j.aiopen.2020.11.001."target="_blank">https://doi.org/10.1016/j.aiopen.2020.11.001. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref6">&uarr;</a></span></td>

      	</tr>

<tr>
        	<td class="number">7</td>
    <td class="reference"><a name="fn7"></a> “Indic TTS”,<em> Indic TTS.</em>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref7">&uarr;</a></span></td

      	</tr>

<tr>
        	<td class="number">8</td>

<td class="reference"><a name="fn8"></a>  Baby, Arun, “A Unified Approach to Speech Synthesis in Indian Languages”, (MS Thesis, IIT Madras, 2019), 1–93,<a href=" https://www.arunbaby.com/assets/docs/MSthesis_2019.pdf."target="_blank"> https://www.arunbaby.com/assets/docs/MSthesis_2019.pdf.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref8">&uarr;</a></span></td>


</tr>
</table>
    </div>
  </div>

      <div class="six wide column empty">
      </div>


    </div>
  </div>
  <!-- Footer -->
  <div class="footer">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="five wide column">
        <h3>About the Study</h3>
        <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Elementum facilisis leovel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.
Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam.</p>
      </div>
      <div class="five wide column">
        <h3>Research Team</h3>
        <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Elementum facilisis leovel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non. Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam.</p>
      </div>
      <div class="four wide column">
        <h3>Copyright and Credits</h3>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2021<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a><br/><a href="https://fonts.google.com/specimen/Barlow" target="_blank">Barlow</a> and <a href="https://fonts.google.com/specimen/Open+Sans" target="_blank">Open Sans</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/cis-india/mozvoice" target="_blank">GitHub</a></p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="sixteen wide column">
        <div style="float: center; clear: both;">
        <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons" style="float: center; clear: both;">
          <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
	</div>
      </div>
    </div>
  </div>
</body>
</html>

<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Making Voices Heard | A study by the Centre for Internet and Society, India, supported by Mozilla Corporation" />
  <!-- Title + CSS + Favicon -->
  <title>Making Voices Heard</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Header -->
  <div class="">
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <!-- Top Navigation Bar -->
  <div class="blue nav">
    <div class="ui container">
      <div class="nav-entries">
        <span id="home-inactive">Home</span> <a href="#design-policy-brief">Design Brief</a> <a href="#design-policy-brief">Policy Brief</a> <a href="#mapping-actors">Mapping Actors</a> <a href="#case-studies">Case Studies</a> <a href="#literature-surveys">Literature Surveys</a> <a href="#resources">Resources</a> <span id="report"><a href="docs/CIS_MakingVoicesHeard_Report.pdf"><i class="fas fa-arrow-circle-down"></i> Get Full Report</a></span>
      </div>
    </div>
  </div>
  <!-- Design Brief and Policy Brief -->
  <div class="grey" id="design-policy-brief">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="six wide column">
        <div class="design-brief">
          <h2>Design Brief</h2>
          <img src="img/DesignBrief.jpg" style="margin-bottom: 10px;" width="100%" />
          <p id="lead"><a href="design-brief.html">Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore</a>.</p>
          <p>Elementum facilisis leo vel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non. Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam. Nulla facilisi etiam dignissim diam quis enim lobortis scelerisque.</p>
        </div>
      </div>
      <div class="two wide column empty">
      </div>
      <div class="six wide column">
        <div class="policy-brief">
          <h2>Policy Brief</h2>
          <img src="img/PolicyBrief.jpg" style="margin-bottom: 10px;" width="100%" />
          <p id="lead"><a href="policy-brief.html">Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore</a>.</p>
          <p>Elementum facilisis leo vel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida
rutrum quisque non. Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam. Nulla facilisi etiam dignissim diam quis enim lobortis scelerisque.</p>
        </div>
      </div>
      <div class="one wide column empty">
      </div>
    </div>
  </div>
  <!-- Mapping Actors -->
  <div class="blue" id="mapping-actors">
    <div class="ui container two column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="nine wide column">
        <h2>Mapping Actors</h2>
	<div id="image">
          <img src="img/ActorsMappingInfographicCropped.jpg" width="90%" />
      	</div>
      </div>
      <div class="five wide column" id="mapping-actors-desc">
        <p id="lead"><a href="mapping-actors.html">To understand the landscape of voice technologies in India, we mapped 27 voice interface developers between 2019 and 2020.</a></p>
      </div>
      <div class="one wide column empty">
      </div>
    </div>
  </div>
  <!-- Case Studies -->
  <div class="grey" id="case-studies">
    <div class="ui container three column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column">
        <h2>Case Studies</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="four wide column" id="case-studies-entries">
          <img src="img/CaseStudy_CommonVoice.jpg" width="100%" />
          <p id="lead"><a href="case-studies/common-voice.html">Common Voice</a></p>
          <p>Short description text</p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="four wide column" id="case-studies-entries">
          <img src="img/CaseStudy_IndicTTS.jpg" width="100%" />
          <p id="lead"><a href="case-studies/indic-tts.html">Indic TTS</a></p>
          <p>Short description text</p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="four wide column" id="case-studies-entries">
          <img src="img/CaseStudy_Niki.jpg" width="100%" />
          <p id="lead"><a href="case-studies/niki.html">Niki</a></p>
          <p>Short description text</p>
      </div>
      <div class="two wide column empty">
      </div>
    </div>
  </div>
  <!-- Literature Surveys -->
  <div class="yellow" id="literature-surveys">
    <div class="ui container two column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column">
        <h2>Literature Surveys</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="six wide column">
        <h3><a href="">Evolution and Typology</a></h3>
        <img src="img/LitSurvey_EvolutionTypology.jpg" style="border-radius: 50%; float: left; margin: 1em 3em 1em 0;" width="30%" />
        <p style="margin: 2em 0 0 0;">Elementum facilisis leo vel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.</p>
      </div>
      <div class="two wide column empty">
      </div>
      <div class="six wide column" id="lit-survey-desc">
        <h3><a href="">Accessibility and Voice Interfaces</a></h3>
        <img src="img/LitSurvey_Accessibility.jpg" style="border-radius: 50%; float: left; margin: 1em 3em 1em 0;" width="30%" />
        <p style="margin: 2em 0 0 0;">Elementum facilisis leo vel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.</p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="six wide column" id="lit-survey-desc">
        <h3><a href="">Languages and Voice Interfaces</a></h3>
        <img src="img/LitSurvey_Languages.jpg" style="border-radius: 50%; float: left; margin: 1em 3em 1em 0;" width="30%" />
        <p style="margin: 2em 0 0 0;">Elementum facilisis leo vel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.</p>
      </div>
      <div class="two wide column empty">
      </div>
      <div class="six wide column" id="lit-survey-desc">
        <h3><a href="">Privacy and Voice Interfaces</a></h3>
        <img src="img/LitSurvey_Privacy.jpg" style="border-radius: 50%; float: left; margin: 1em 3em 1em 0;" width="30%" />
        <p style="margin: 2em 0 0 0;">Elementum facilisis leo vel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.</p>
      </div>
      <div class="one wide column empty">
      </div>
    </div>
  </div>
  <!-- Resources -->
  <div class="grey" id="resources">
    <div class="ui container two column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column">
        <h2>Resources</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="four wide column">
        <h4>&nbsp;</h4>
        <p>Browse here for a selection of the latest research on voice interfaces, in India and across the world, and to download sections of the report. </p>
        <p></p>
      </div>
      <div class="five wide column">
        <h4>Report</h4>
        <p><a href="">Open voice data for all: Making speech data in Indian languages more accessible, Voice Technologies Working Group</a></p>
        <p><a href="">“Ok Google: How is voice making technology more accessible in India?” WHITEPAPER Voice, the bridge to "Bharat"</a></p>
        <p><a href="">‘Okay google, what about my privacy?’: User's privacy perceptions and acceptance of voice based digital assistants</a></p>
        <p><a href="">"Accessibility Came by Accident": Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities</a></p>
        <p><a href="">Alexa, Siri, Cortana, and More: An Introduction to Voice Assistants</a></p>
        <p><a href="">How Might Voice Assistants Raise Our Children?</a></p>
        <p><a href="">Using Voice Interfaces to Make Products More Inclusive</a></p>
        <p><a href="">A Voice User Interface for Low-literacy Users in a Rural Community</a></p>
        <p><a href="">Design Lessons from Creating a Mobile-based Community Media Platform in Rural India</a></p>
        <p></p>
      </div>
      <div class="five wide column">
        <h4>Additional Readings</h4>
        <p><a href="">Elementum facilisis leo vel fringilla est ullamcorper</a></p>
        <p><a href="">Faucibus scelerisque eleifend donec pretium</a></p>
        <p><a href="">Nunc vel risus commodo viverra</a></p>
        <p><a href="">In hendrerit gravida rutrum quisque non</a></p>
        <p><a href="">Egestas sed sed risus pretium</a></p>
        <p><a href="">Nulla porttitor massa id neque aliquam</a></p>
        <p></p>
      </div>
      <div class="one wide column empty">
      </div>
    </div>
  </div>
  <!-- Footer -->
  <div class="footer">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="five wide column">
        <h3>About the Study</h3>
        <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Elementum facilisis leovel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.
Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam.</p>
      </div>
      <div class="five wide column">
        <h3>Research Team</h3>
        <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Elementum facilisis leovel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non. Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam.</p>
      </div>
      <div class="four wide column">
        <h3>Copyright and Credits</h3>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2021<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a><br/><a href="https://fonts.google.com/specimen/Barlow" target="_blank">Barlow</a> and <a href="https://fonts.google.com/specimen/Open+Sans" target="_blank">Open Sans</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/cis-india/mozvoice" target="_blank">GitHub</a></p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="sixteen wide column">
        <div style="float: center; clear: both;">
        <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons" style="float: center; clear: both;">
          <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
	</div>
      </div>
    </div>
  </div>
</body>
</html>
