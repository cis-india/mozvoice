<!DOCTYPE html>
<html>
<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Making Voices Heard | A study by the Centre for Internet and Society, India, supported by Mozilla Corporation" />
  <!-- Title + CSS + Favicon -->
  <title>Making Voices Heard</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Header -->
  <div>
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <!-- Top Navigation Bar -->
  <div class="blue nav">
    <div class="ui container">
      <div class="nav-entries">
        <a href="index.html" id="home">Home</a> <a href="design-brief.html">Design Brief</a> <span id="inactive">Policy Brief</span> <a href="mapping-actors.html">Mapping Actors</a> <a href="#case-studies">Case Studies</a> <a href="#literature-surveys">Literature Surveys</a> <a href="#resources">Resources</a> <span id="report"><a href="docs/CIS_MakingVoicesHeard_Report.pdf"><i class="fas fa-arrow-circle-down"></i> Get Full Report</a></span>
      </div>
    </div>
  </div>
  <!-- Title -->
  <div class="grey">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column text">
        <h2>Indic TTS</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="nine wide column text">

        <h3 id="about">About</h3>

        <p><strong> “The amount of work in the speech domain for Indian languages is comparatively lower than that for other languages.”<sup class="superscript"><a href="#fn1">1</a></sup><a name="ref1"></a> </strong></p>

          <p> The Indic TTS consortium was created and funded by the Department of Electronics and Information Technology, Ministry of Communications and Information Technology,<sup class="superscript"><a href="#fn2">2</a></sup><a name="ref2"></a> Government of India, to create more Indic language speech data to reduce the data divide between English and Indian languages. The Indic TTS website describes this as “a project on developing text-to-speech (TTS) synthesis systems for Indian languages, improving quality of synthesis, as well as small footprint TTS integrated with disability aids and various other applications”.<sup class="superscript"><a href="#fn3">3</a></sup><a name="ref3"></a>
    In a recently published paper on voice technologies, researchers involved in the TTS project stated that the paucity of content in Indian languages was stark when it came to the multimedia domain and digital assistants,<sup class="superscript"><a href="#fn4">4</a></sup><a name="ref4"></a> thereby highlighting the need for speech data in Indian languages. This paucity was attributed to the lack of localisation of technologies like optical character recognition (Optical character recognition or OCR is the electronic or mechanical conversion of images of typed, handwritten, or printed text into machine-encoded text in a way that can be read by speech-to-text systems)<sup class="superscript"><a href="#fn5">5</a></sup><a name="ref5"></a> neural machine translation(neural machine translation uses computing systems that mimic the working of the human brain to predict the order of words in sentences)<sup class="superscript"><a href="#fn6">6</a></sup><a name="ref6"></a> and text-to-speech systems.The speech data for the database was collected through the joint efforts of the 13 consortium members: IIT Madras, IIIT Hyderabad, IIT Kharagpur, IISc Bangalore, CDAC Mumbai, CDAC Thiruvananthapuram, IIT Guwahati, CDAC Kolkata, CDAC Pune, SSNCE Chennai, DA-IICT Gujarat, IIT Mandi, and PESIT Bangalore. The database and text-to-speech synthesisers were built for 13 languages, namely, Assamese, Bengali, Bodo, Gujarati, Hindi, Kannada, Malayalam, Manipuri, Marathi, Odia, Rajasthani, Tamil, and Telugu.</p>
    <h3 id="methodology">Methodology and process</h3>
    <h4>Language and text selection</h4>
        <p></p>
        <p> The process of creating voice datasets in Indian languages involved several steps, beginning with the selection of languages that are the focus of the project and then building speech technologies using the voice datasets. The selection of the 13 languages was based on the following criteria: optimal text selection, speaker selection, pronunciation variation, recording specification, text correction for handling out-of-the-vocabulary words, and data verification.<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> To ensure the quality of data, characteristics that affect speech synthesis quality such as encoding (converting one form of data to another), sampling rate (number of samples of audio recorded every second) etc. were considered. The sentences for the speech recordings were taken through web crawlers from newspaper reports, Wikipedia pages, websites, and blogs in the respective Indian language. To achieve good coverage of topics and words, sentences were also taken from different types of literature, including children’s stories, science writing, tourism content, etc. Care was also taken to ensure that the texts were commonly used, free of errors, easy to read, and covered a wide range of words and syllables. Code-mixed sentences were avoided.</p>
        <p>
        <h4>Speaker selection and recording </h4>
        <p> To create speech recordings for the datasets, two voice talents – a male and a female – were chosen for each language. The recordings were made in a studio room without noise or echo for clarity of the recordings. The voice talents were voice professionals who were either voice artists or newsreaders to ensure clarity in the pronunciation and diction. They were given breaks every 45 minutes to avoid fatigue. In each recording, individual sentences were isolated. A total of 40 hours of speech data was collected for a given language – 20 hours of Indian monolingual/single language data (10 hours each of male and female voice data) and 20 hours of English data recorded by first language speakers (10 hours each of male and female voice data). The recorded files were stored in .wav format to ensure that the recordings were of high sound quality.</p>

      <h4>Text-to-speech synthesis</h4>
        <p>One of the researchers in the Indic TTS project defines text-to-speech synthesis as the “process of converting an arbitrary input text to its corresponding speech output”. In the context of Indian languages, the TTS system uses syllables or phonemes (units of sound that can distinguish one word from another in a particular language) as a sub-word unit (where words are split into smaller words that occur more frequently). The three major components involved in building a TTS system are text parsing, speech segmentation, and speech modelling.<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a> Simply put, the objective of a TTS system is to convert text into speech output. TTS systems can be divided into two types – domain-specific and vocabulary independent. In the case of domain specific systems, the words/text to be synthesised should be limited to a particular domain, such as banking or railway broadcast, while for vocabulary independent systems, any text will work. </p>

          <h3 id="Languages">Languages</h3>
        <p>The main motivation for the project was to address the unavailability of voice data in Indian languages. The functioning of a TTS system is dependent on the training data that is fed into the system, which includes speech .wav files along with a transcript of the corresponding text. The TTS project aims to develop text-to-speech synthesisers for 13 Indian languages, which could help researchers and developers work on Indian voice applications. One of the goals of the project is to make the voice of the text-to-speech system sound as natural and understandable as possible. The first phase of the project concentrated on three languages (3 Indo-Aryan languages and 3 Dravidian languages), the second phase added 7 more languages to the study.</p>

        <h3 id="Access and accessibility">Access and accessibility</h3>
        <p>The TTS project was started with the idea of giving people with disabilities access to regional information on the internet, such as news reports in Indian languages. Since the consortium is a publicly funded project, the datasets and research have been made public on its website. The datasets are available free of cost to researchers – they just need to log in to the website to use them. Start-ups and businesses that want to use the data can sign a Memorandum Of Understanding with Indic TTS and access the data.</p>

      <h3 id="Privacy and data collection">Privacy and data collection</h3>
        <p>As stated earlier, the text data for training the systems was taken from publicly available sources such as online news portals, Wikipedia pages, websites, and blogs; hence, privacy and data protection are not significant concerns. Additionally, with regard to the speech data, the readings were done by professional voice artists who recorded sounds and words for the project based on a script provided to them by the researchers.</p>

     <h3 id="Challenges">Challenges</h3>

        <p>One of the main challenges for the researchers was ensuring that the datasets were comprehensive and accurate while keeping the cost of creating and accessing them low. Since the project was publicly funded, the researchers needed to work with the available funding and ensure that the research was accessible and free. As stated earlier, the data and the research are open to researchers,  and start-ups can request the data after signing an MOU. Another challenge was making the speech output sound more human-like and less robotic, similar to the heavily funded and data-rich interfaces of Amazon and Google. The other challenge was making the output speech systems context-specific, such as with children’s books.
        Voice interfaces provide accessibility support for individuals who are unable to see the screen or understand the text. However, no applications other than Google and Amazon claim to provide accessibility features. Amazon Echo’s website lists the various features that customers with vision, hearing, mobility, and speech accessibility needs could use. <sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a> Google Home provides accessibility features that allow the individual to control appliances and entertainment, make phone calls, broadcast messages, and manage tasks in addition to its voice assistant.<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a></p>

      <h3 id="Future of Indic TTS">Future of Indic TTS</h3>
        <p>The project looks at continuing research and data collection with the help of government funding. Given the scale and amount of funding needed for such projects, including the requirement of infrastructure and trained human resources, the government is the primary source of funding. With the new funding from the Ministry of Electronics and Information Technology, the researchers at IITM have started a project to make English lecture videos available in Indian languages. The objective of this project is to make lectures in different domains, like humanities, healthcare, etc., freely accessible to students in their languages. This is a small-scale project, and Indic TTS hopes to expand it to more languages and subjects. </p>
        <br />
    <i> Disclaimer: This is an independent case study conducted as a part of the Making Voices Heard Project, supported by the Mozilla Corporation. The researchers have not received any external remuneration as a part of this case study, and claim no conflict of interest.</i>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="five wide column meta">
        <p><span id="grey">Research and Writing by</span> <br />Shweta Mohandas and Saumyaa Naidu
          <br />
        <span id="grey">Review and Editing by</span> <br />Puthiya Purayil Sneha, <br /><span id="grey">and</span> Torsha Sarkar<br />
        <span id="grey">Research Inputs by</span> <br />Sumandro Chattapadhyay<br />
	       <br />
        <a href="docs/MozVoice_PolicyBrief_02.pdf"><i class="fas fa-arrow-circle-down" style="color: black;" ></i> Download Policy Brief</a></p>
        <br />
         <hr />
	       <br />
        <p><span style="line-height: 3em;">CONTENTS</span></p>
	      <p><a href="#about"><strong>About</strong></a></p>
        <p><a href="#methodology"><strong>Methodology and Process</strong></a></p>
        <p><a href="#Languages"><strong>Languages</strong></a></p>
        <p><a href="#Access and assessibility"><strong>Access and accessibility</strong></a></p>
        <p><a href="#Privacy and data collection"><strong>Privacy and data collection </strong></a></p>
        <p><a href="#Challenges"><strong>Challenges</strong></a></p>
        <p><a href="#Future of Indic TTS"><strong>Future of Indic TTS</strong></a></p>
        <p><a href="#emerging-uses-of-voice-and-questions-about-privacy-and-data-protection">Emerging Uses of Voice and Questions about Privacy and Data Protection</a></p>
        <p><a href="#policy-recommendations"><strong>Policy Recommendations</strong></a></p>
        <p><a href="#the-impetus-for-public-funded-research">The Impetus for Public-Funded Research</a></p>
        <p><a href="#more-funding-for-accessibility-research">More Funding for Accessibility Research</a></p>
        <p><a href="#more-clarity-from-personal-data-protection-bill-about-the-regulation-of-voice-data">More Clarity from Personal Data Protection Bill about the Regulation of Voice Data</a></p>
        <p><a href="#the-need-for-more-diverse-voice-datasets">The Need for More Diverse Voice Datasets</a></p>
        <p><a href="#The need for more funding towards community-led voice dataset collection">The Need for More Funding Towards Community-Led Voice Dataset Collection</a></p>
        <p><a href="#conclusion"><strong>Conclusion</strong></a></p>
        <p><a href="#appendix"><strong>Appendix - Timeline of Key Voice Interface Events</strong></a></p>
        <p><a href="#government-initiatives">Government Initiatives</a></p>
</div>

<div class="ten wide column content">
</div>
<div class="ten wide column content">
  <br />
<h3>Notes</h3>
<table class="footnote">
  <tr>
    <td class="number">1</td>
<td class="reference"><a name="fn1"></a> Baby, Arun et al., "Resources for Indian Languages", In <em>Proceedings of CBBLR workshop, International Conference on Text, Speech and Dialogue</em>. Springer, 2016.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref1">&uarr;</a></span></td>

      	</tr>

<tr>
        	<td class="number">2</td>
      	<td class="reference"><a name="fn2"></a>“Indic TTS”, Indic TTS;Department of Electronics and Information Technology (DEITY) has been renamed to Ministry of Electronics and Information Technology (MEITY) 03 November 2021, <a href="https://www.iitm.ac.in/donlab/tts/ " target="_blank"> https://www.iitm.ac.in/donlab/tts/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref2">&uarr;</a></span></td>
      	</tr>


<tr>
        	<td class="number">3</td>
    <td class="reference"><a name="fn3"></a> “Indic TTS”,<em> Indic TTS.</em> Accessed 3 November 2021. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref3">&uarr;</a></span></td

      	</tr>


<tr>
        	<td class="number">4</td>
    <td class="reference"><a name="fn4"></a>Baby Arun, "Resources for Indian Languages"&nbsp;&nbsp;<span class="internal-nav"><a href="#ref4">&uarr;</a></span></td

      	</tr>
<tr>
        	<td class="number">5</td>

<td class="reference"><a name="fn5"></a> “An Introduction to Optical Character Recognition for Beginners”, Towards Data Science, accessed 5 January 2022, <a href="https://towardsdatascience.com/an-introduction-to-optical-character-recognition-for-beginners-14268c99d60"target="_blank">https://towardsdatascience.com/an-introduction-to-optical-character-recognition-for-beginners-14268c99d60 </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref5">&uarr;</a></span></td>

      	</tr>

<tr>
        	<td class="number">6</td>

<td class="reference"><a name="fn6"></a> Tan,Zhixing et al., “Neural machine translation: A review of methods, resources, and tools”, AI Open Volume 1.(2020):5-21, <a href="https://doi.org/10.1016/j.aiopen.2020.11.001."target="_blank">https://doi.org/10.1016/j.aiopen.2020.11.001. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref6">&uarr;</a></span></td>

      	</tr>

<tr>
        	<td class="number">7</td>
    <td class="reference"><a name="fn7"></a> “Indic TTS”,<em> Indic TTS.</em>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref7">&uarr;</a></span></td

      	</tr>

<tr>
        	<td class="number">8</td>

<td class="reference"><a name="fn8"></a>  Baby, Arun, “A Unified Approach to Speech Synthesis in Indian Languages”, (MS Thesis, IIT Madras, 2019), 1–93,<a href=" https://www.arunbaby.com/assets/docs/MSthesis_2019.pdf."target="_blank"> https://www.arunbaby.com/assets/docs/MSthesis_2019.pdf.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref8">&uarr;</a></span></td>


</tr>
<tr>
<td class="number">13</td>
<td class="reference"><a name="fn13"></a> Rangarajan, K., “Voice to Cart: Powering your E-commerce App with Voice”, <em> Slang Labs </em>, 6 October 2020, accessed 20 October 2021, <a href=" https://www.slanglabs.in/blog/voice-to-cart-powering-your-ecommerce-app-with-voice."target="_blank">https://www.slanglabs.in/blog/voice-to-cart-powering-your-ecommerce-app-with-voice.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref13">&uarr;</a></span></td>
</tr>
  <tr>
<td class="number">14</td>
<td class="reference"><a name="fn14"></a> Limited, J. H. T., How Haptik Automated Grofers' Customer Support in Less than 48 Hours”,<em> Haptik </em>, accessed 20 October 2021, <a href=" https://www.haptik.ai/resources/case-study/grofers-case-study..target="_blank”>https://www.haptik.ai/resources/case-study/grofers-case-study</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref14">&uarr;</a></span></td>

</tr>
  <tr>
<td class="number">15</td>

<td class="reference"><a name="fn15"></a> Limited, Schwartz, E. H., “Indian E-commerce Giant Flipkart Expands English and HINDI Voice Search Platform-Wide”, <em> Voicebot.ai </em>, 4 March 2021, <a href=" https://voicebot.ai/2021/03/04/indian-e-commerce-giant-flipkart-expands-english-and-hind .target="_blank”>https://voicebot.ai/2021/03/04/indian-e-commerce-giant-flipkart-expands-english-and-hind/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref15">&uarr;</a></span></td>

</tr>
  <tr>
<td class="number">16</td>
<td class="reference"><a name="fn16"></a> Limited, Schwartz, E. H., “Tech Desk, “Google Assistant Now in Hindi: Here's How to Activate and Use”,. <em> The Indian Express </em>, 15 March. (2018, March 15).  <a href=" https://indianexpress.com/article/technology/social/google-assistant-now-available-in-hindi-heres-how-to-activate-and-use-5098595.target="_blank”>https://indianexpress.com/article/technology/social/google-assistant-now-available-in-hindi-heres-how-to-activate-and-use-5098595 /.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref16">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">17</td>
<td class="reference"><a name="fn17"></a> Singh, M., (2019, September 18). “Amazon's Alexa Now Speaks Hindi”,. <em> TechCrunch </em>, 18 September 2019,<a href="  https://techcrunch.com/2019/09/18/amazon-alexa-hindi-india .target="_blank”>https://techcrunch.com/2019/09/18/amazon-alexa-hindi-india.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref17">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">18</td>
<td class="reference"><a name="fn18"></a> “Accessibility Features for Alexa”, <em> Amazon </em>, accessed 20 October 2021, <a href=" https://www.amazon.in/gp/help/customer/display.html?nodeId=202158280.target="_blank”>https://www.amazon.in/gp/help/customer/display.html?nodeId=202158280</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref18">&uarr;</a></span></td>

</tr>

<tr>
    <td class="number">19</td>
   <td class="reference"><a name="fn19"></a> “Accessibility features on Google nest or home devices”, <em> Google Nest Help </em>, <a href=" https://support.google.com/googlenest/answer/9286728?hl=en><a target="_blank”>https://support.google.com/googlenest/answer/9286728?hl=en</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref19">&uarr;</a></span></td>

</tr>


<tr>
<td class="number">20</td>
<td class="reference"><a name="fn20"></a> Guardian News and Media, “’Alexa, Are You Invading My Privacy?’ – The Dark Side of our Voice Assistants”, <em> The Guardian </em>, 9 October 2019, = <a href=" https://www.theguardian.com/technology/2019/oct/09/alexa-are-you-invading-my-privacy-the-dark-side-of-our-voice-assistantstarget="_blank”>https://www.theguardian.com/technology/2019/oct/09/alexa-are-you-invading-my-privacy-the-dark-side-of-our-voice-assistants</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref19">&uarr;</a></span></td>

</tr>

<tr>
<td class="number">21</td>
<td class="reference"><a name="fn21"></a>The Information Technology Act, 2000.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref21">&uarr;</a></span></td>

</tr>

<tr>
<td class="number">22</td>
<td class="reference"><a name="fn22"></a>Information Technology (Reasonable Security Practices and Procedures and Sensitive Personal Data or Information) Rules, 2011.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref22">&uarr;</a></span></td>

</tr>

   <tr>
<td class="number">23</td>
<td class="reference"><a name="fn23"></a>The Personal Data Protection Bill, 2019. <a href=" http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf target="_blank”> http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref23">&uarr;</a></span></td>


</tr>
<tr>
<td class="number">24</td>
<td class="reference"><a name="fn24"></a> Ministry of Communications, “Internet Connectivity in Rural India. Unstarred Question No. 594 To Be Answered On 16th September, 2020, 2020”, 16 September, <a href=" http://164.100.24.220/loksabhaquestions/annex/174/AU594.pdftarget="_blank”>http://164.100.24.220/loksabhaquestions/annex/174/AU594.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref24">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">25</td>
<td class="reference"><a name="fn25"></a> Ministry of Communications, “Internet Connectivity in Rural India”.nbsp;&nbsp;<span class="internal-nav"><a href="#ref25">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">26</td>
<td class="reference"><a name="fn26"></a> Nandita Mathur, "India now has over 500 million active Internet users: IAMAI", Mint, 05 May 2020<a href="  https://www.livemint.com/news/india/india-now-has-over-500-million-active-internet-users-iamai-11588679804774.html.target="_blank”>https://www.livemint.com/news/india/india-now-has-over-500-million-active-internet-users-iamai-11588679804774.html.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref26">&uarr;</a></span></td>
</tr>
   <tr>
<td class="number">27</td>
<td class="reference"><a name="fn27"></a>Dr Rajesh Tandon, "One Device Households", The Times of India, 17 July 2020.<a href=" https://timesofindia.indiatimes.com/blogs/voices/one-device-households.target="_blank”>https://timesofindia.indiatimes.com/blogs/voices/one-device-households</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref27">&uarr;</a></span></td>
</tr>
  <tr>
<td class="number">28</td>
<td class="reference"><a name="fn28"></a>“Smyth, T. N. (2010). Where There’s a Will There’s a Way: Mobile Media Sharing in Urban India. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems<a href=https://www.researchgate.net/publication/221514114_Where_there's_a_will_there's_a_way_Mobile_media_sharing_in_urban_indiatarget="_blank”>https://www.researchgate.net/publication/221514114_Where_there's_a_will_there's_a_way_Mobile_media_sharing_in_urban_india </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref28">&uarr;</a></span></td>

</tr>
    <tr>
<td class="number">29</td>
<td class="reference"><a name="fn29"></a>Through our interviews we understood that developers and researchers alike were able to get voice data in different languages through participating in competitions organised by Google and Microsoft.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref29">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">30</td>

<td class="reference"><a name="fn30"></a>A low resource language means a language that does not have or has only few data resources. This makes it even more difficult to develop machine-learning based systems for these languages.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref30">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">31</td>
<td class="reference"><a name="fn31"></a>“Indic TTS”, Indic TTS, accessed 3 November 2021,<ahref=https://www.iitm.ac.in/donlab/tts/.target="_blank”>https://www.iitm.ac.in/donlab/tts/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</a></span></td>
</tr>
  <tr>
<td class="number">32</td>
<td class="reference"><a name="fn32"></a>“Accessibility of Government Websites in India: A Report”, The Centre for Internet and Society India, 2012, <ahref=https://cis-india.org/accessibility/accessibility-of-government-websites-in-indiatarget="_blank”>https://cis-india.org/accessibility/accessibility-of-government-websites-in-india</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref32">&uarr;</a></span></td>

</tr>
  <tr>
<td class="number">33</td>

<td class="reference"><a name="fn33"></a>Agrawal, G., Kumar, D., and Singh, M., “Assessing the Usability, Accessibility, and Mobile Readiness of E-government Websites: A Case Study in India”, Universal Access in the Information Society (2021): 1–12. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</a></span></td>

</tr>
  <tr>
<td class="number">34</td>

<td class="reference"><a name="fn34"></a>The Mobile Ok checked by W3C performs various tests on a web page to determine the level of mobile-friendliness. The tests are defined in the mobileOK Basic Tests 1.0 specification. A web page is considered mobileOK only when it passes all the tests.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref34">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">35</td>

<td class="reference"><a name="fn35"></a>“Nath, D., “Mandatory Aarogya Setu App Not Accessible to Persons with Disabilities”, <em> The Hindu,</em> 2 May 2020,<ahref=https://www.thehindu.com/news/national/coronavirus-mandatory-aarogya-setu-app-not-accessible-to-persons-with-disabilities/article31489933.ece.target="_blank”>https://www.thehindu.com/news/national/coronavirus-mandatory-aarogya-setu-app-not-accessible-to-persons-with-disabilities/article31489933.ece.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref35">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">36</td>
<td class="reference"><a name="fn36"></a>“Nath, D., “Mandatory Aarogya Setu <em> The Hindu,</em> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref36">&uarr;</a></span></td>

</tr>

<tr>
<td class="number">37</td>

<td class="reference"><a name="fn37"></a>“Arogya Setu IVRS”,<ahref=https://www.mohfw.gov.in/pdf/AAROGYASETUIVRS1921.pdftarget="_blank”>https://www.mohfw.gov.in/pdf/AAROGYASETUIVRS1921.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref37">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">38</td>
<td class="reference"><a name="fn38"></a>“Nath, D., “Mandatory Aarogya Setu <em> The Hindu,</em> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref38">&uarr;</a></span></td>

</tr>
</tr>
<tr>
<td class="number">39</td>
<td class="reference"><a name="fn39"></a>Kulkarni, A., “Indian Banking – Adoption of Voice Biometrics”,2020,<ahref=https://kaizenvoiz.com/wp-content/uploads/2020/11/Kaizen-white-paper-for-Indian-banking-ver-6.1.pdftarget="_blank”>https://kaizenvoiz.com/wp-content/uploads/2020/11/Kaizen-white-paper-for-Indian-banking-ver-6.1.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref39">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">40</td>
<td class="reference"><a name="fn39"></a>Kulkarni, A., “Indian Banking – Adoption of Voice Biometrics”,2020,<ahref=https://kaizenvoiz.com/wp-content/uploads/2020/11/Kaizen-white-paper-for-Indian-banking-ver-6.1.pdftarget="_blank”>https://kaizenvoiz.com/wp-content/uploads/2020/11/Kaizen-white-paper-for-Indian-banking-ver-6.1.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref39">&uarr;</a></span></td>

</tr>
<tr>
<td class="number">41</td>

<td class="reference"><a name="fn41"></a>Ali, F. and Mohandas, S., “The Compulsive Patent Hoarding Disorder”, <em> The Hindu </em>, 24 March 2017,<ahref=https://www.thehindu.com/opinion/op-ed/the-compulsive-patent-hoarding-disorder/article17617888.ece.target="_blank”>https://www.thehindu.com/opinion/op-ed/the-compulsive-patent-hoarding-disorder/article17617888.ece.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref41">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">42</td>
<td class="reference"><a name="fn42"></a>Ali, A, “Scheme for Implementation of Persons with Disabilities Act (SIPDA) Has Been Reduced from Rs 315 Crore”, <em> Indian Express </em>, 30 January 2021,20<ahref=https://indianexpress.com/article/lifestyle/life-style/pandemic-has-hit-persons-with-disabilities-hardest-union-budget-should-address-their-concerns-7167840/.target="_blank”>https://indianexpress.com/article/lifestyle/life-style/pandemic-has-hit-persons-with-disabilities-hardest-union-budget-should-address-their-concerns-7167840/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref42">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">43</td>
<td class="reference"><a name="fn43"></a>Ali, “Scheme for Implementation”, <em> Indian Express </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref43">&uarr;</a></span></td>

</tr>

</tr>
<tr>
<td class="number">44</td>
<td class="reference"><a name="fn44"></a>Ali, “Scheme for Implementation”, <em> Indian </em> Express.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref44">&uarr;</a></span></td>

</tr>

<tr>
<td class="number">45</td>
<td class="reference"><a name="fn45"></a>Outlook, “Progress of Accessible India Campaign Rather slow: Parl Panel.” <em> Outlook </em>, 6 August 2021, <ahref=https://www.outlookindia.com/newsscroll/progress-of-accessible-india-campaign-rather-slow-parl-panel/2136476.target="_blank”>https://www.outlookindia.com/newsscroll/progress-of-accessible-india-campaign-rather-slow-parl-panel/2136476.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref45">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">46</td>
<td class="reference"><a name="fn46"></a>Section 3(7), The Personal Data Protection Bill, 2019,<ahref=.http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdftarget="_blank”>.http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref46">&uarr;</a></span></td>
</tr>

<tr>
<td class="number">47</td>
<td class="reference"><a name="fn46"></a>Section 26(1), The Personal Data Protection Bill, 2019,<ahref=.http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdftarget="_blank”>.http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref46">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">48</td>
<td class="reference"><a name="fn48"></a>Section 26(3), The Personal Data Protection Bill, 2019,<ahref=.http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdftarget="_blank”>.http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref48">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">49</td>
<td class="reference"><a name="fn49"></a>“Making Voices Heard: Mapping Actors,” <em> Making Voices Heard </em>, accessed 02 February 2022,<ahref=http://voice.cis-india.org/mapping-actors.htmltarget="_blank”>http://voice.cis-india.org/mapping-actors.html</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref49">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">50</td>
<td class="reference"><a name="fn50"></a>“Ahaskar, A. “Voice biometrics are Cleverer Now, But Still Need More Work”, <em> Mint </em>, 6 February 2020, <ahref=https://www.livemint.com/technology/tech-news/voice-biometrics-are-cleverer-now-but-still-need-more-work-11581011267941.html.target="_blank”>https://www.livemint.com/technology/tech-news/voice-biometrics-are-cleverer-now-but-still-need-more-work-11581011267941.html.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref50">&uarr;</a></span></td>
</tr>

<tr>
<td class="number">51</td>
<td class="reference"><a name="fn51"></a>WP Company. “The Accent GAP: How Amazon's and Google's smart SPEAKERS Leave Certain Voices Behind”, <em> The Washington Post </em>, 19 July2018,<ahref=https://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/.target="_blank”>https://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref51">&uarr;</a></span></td>
</tr>

<tr>
<td class="number">52</td>
<td class="reference"><a name="fn52"></a>Interview, Anonymous, in person, Bangalore, March 3 2020.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref52">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">53</td>
<td class="reference"><a name="fn53"></a>“Making Voices Heard: Common Voice Case Study,” <em> Making Voices Heard </em>, accessed 02 February 2022,<ahref=http://voice.cis-india.org/case-studies/common-voice.html target="_blank”>http://voice.cis-india.org/case-studies/common-voice.html </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref53">&uarr;</a></span></td>
</tr>

<tr>
<td class="number">54</td>
<td class="reference"><a name="fn54"></a>“Common Voice by Mozilla.” <em> Common Voice </em>, accessed January 4, 2022,<ahref=ttps://commonvoice.mozilla.org/en/datasets.target="_blank”>ttps://commonvoice.mozilla.org/en/datasets.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref54">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">55</td>
<td class="reference"><a name="fn55"></a>“Making Voices Heard: Common Voice Case Study,” <em> Making Voices Heard </em>, accessed 02 February 2022,<ahref=http://voice.cis-india.org/case-studies/common-voice.html target="_blank”>http://voice.cis-india.org/case-studies/common-voice.html </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref55">&uarr;</a></span></td>
</tr>

<tr>
<td class="number">56</td>
<td class="reference"><a name="fn56"></a>“How Rwanda is making voice tech more open”, <em> Mozilla Foundation </em>, 16 September2020,<ahref=https://foundation.mozilla.org/en/blog/how-rwanda-making-voice-tech-more-open/.target="_blank”>https://foundation.mozilla.org/en/blog/how-rwanda-making-voice-tech-more-open/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref56">&uarr;</a></span></td>
</tr>

<tr>
<td class="number">57</td>
<td class="reference"><a name="fn57"></a>“How Rwanda is” Mozilla Foundation. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref57">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">58</td>
<td class="reference"><a name="fn58"></a>“How Rwanda is” Mozilla Foundation.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref58">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">59</td>
<td class="reference"><a name="fn59"></a>“Welcome to CGNet Swara”, <em> CG Net Swara </em>,,<ahref=http://cgnetswara.org/,16 September 2020,.target="_blank”>http://cgnetswara.org/,16 September 2020,</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref59">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">60</td>
<td class="reference"><a name="fn60"></a>Majumdar, M., “This Indian Language Can Be Written by Only 100 People”, <em> The Hindu </em>, 31 March 2018, ,<ahref=https://www.thehindu.com/society/this-indian-language-can-be-written-by-only-100-people/article23384526.ece.target="_blank”>https://www.thehindu.com/society/this-indian-language-can-be-written-by-only-100-people/article23384526.ece.,</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref60">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">61</td>
<td class="reference"><a name="fn61"></a>For example there have been numerous news reports about the Umang App being enabled with multilingual voice support, however at the time of writing this policy brief there have been no reports of its implementation and use.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref61">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">62</td>
<td class="reference"><a name="fn62"></a>“Voice-based Social Media”, <em> Awaaz.De </em>,<ahref=https://hci.stanford.edu/research/voice4all/ 16 September 2020,target="_blank”>https://hci.stanford.edu/research/voice4all/ 16 September 2020,</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref62">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">63</td>
<td class="reference"><a name="fn63"></a>Kazakos, K., Asthana, S., Balaam, M., Duggal, M., Holden, A., Jamir, L., Kannuri, N. K., Kumar, S., Manindla, A. R., Manikam, S. A., Murthy, G. V. S., Nahar, P., Phillimore, P., Sathyanath, S., Singh, P., Singh, M., Wright, P., Yadav, D., and Olivier, P., “A Real-time IVR Platform for Community Radio'', proceedings of the 2016 CHI Conference on Human Factors in Computing System, 2016<ahref=https://doi.org/10.1145/2858036.2858585arget="_blank”>https://doi.org/10.1145/2858036.2858585</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref63">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">64</td>
<td class="reference"><a name="fn64"></a>“Arogya Setu IVRS”,<ahref=https://www.mohfw.gov.in/pdf/AAROGYASETUIVRS1921.pdftarget="_blank”>https://www.mohfw.gov.in/pdf/AAROGYASETUIVRS1921.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref64">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">65</td>
<td class="reference"><a name="fn65"></a>“Invitation to Bid for Appointment of Partner Agency (Vendor 5)”, <em> Umang </em>, <ahref=https://www.meity.gov.in/writereaddata/files/tender_upload/UMANG%20RFP_AI-Bot.pdftarget="_blank”>https://www.meity.gov.in/writereaddata/files/tender_upload/UMANG%20RFP_AI-Bot.pdf</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref65">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">66</td>
<td class="reference"><a name="fn66"></a>Agarwal, Surabhi, “Move Over Alexa and Siri, ‘Hey Umang’ to Deliver Govt Services Through Voice Commands Soon”, <em> Economic Times </em>, 05 April 2021,<ahref=https://economictimes.indiatimes.com/tech/technology/move-over-alexa-andtarget="_blank”>https://economictimes.indiatimes.com/tech/technology/move-over-alexa-and</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref66">&uarr;</a></span></td>
</tr>
<tr>
<td class="number">67</td>
<td class="reference"><a name="fn67"></a>Shivakumar, C., “TN Agency to Develop First Voice User Interface by Government in Tamil”, <em> New Indian Express </em>, 9 October 2020, ,<ahref=https://www.newindianexpress.com/states/tamil-nadu/2020/oct/09/tn-agency-to-develop-first-voice-user-interface-by-government-in-tamil-2208051.html.target="_blank”>https://www.newindianexpress.com/states/tamil-nadu/2020/oct/09/tn-agency-to-develop-first-voice-user-interface-by-government-in-tamil-2208051.html.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref67">&uarr;</a></span></td></tr>
</table>
    </div>
  </div>

      <div class="six wide column empty">
      </div>


    </div>
  </div>
  <!-- Footer -->
  <div class="footer">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="five wide column">
        <h3>About the Study</h3>
        <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Elementum facilisis leovel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non.
Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam.</p>
      </div>
      <div class="five wide column">
        <h3>Research Team</h3>
        <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Elementum facilisis leovel fringilla est ullamcorper. Faucibus scelerisque eleifend donec pretium. Nunc vel risus commodo viverra. In hendrerit gravida rutrum quisque non. Egestas sed sed risus pretium. Nulla porttitor massa id neque aliquam.</p>
      </div>
      <div class="four wide column">
        <h3>Copyright and Credits</h3>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2021<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a><br/><a href="https://fonts.google.com/specimen/Barlow" target="_blank">Barlow</a> and <a href="https://fonts.google.com/specimen/Open+Sans" target="_blank">Open Sans</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/cis-india/mozvoice" target="_blank">GitHub</a></p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="sixteen wide column">
        <div style="float: center; clear: both;">
        <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons" style="float: center; clear: both;">
          <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
	</div>
      </div>
    </div>
  </div>
</body>
</html>
