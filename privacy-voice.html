<!DOCTYPE html>
<html><!DOCTYPE html>
<html>
<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Making Voices Heard | A study by the Centre for Internet and Society, India, supported by Mozilla Corporation" />
  <!-- Title + CSS + Favicon -->
  <title>Making Voices Heard</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Header -->
  <div>
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <!-- Top Navigation Bar -->
  <div class="blue nav">
    <div class="ui container">
      <div class="nav-entries">
        <a href="index.html" id="home">Home</a> <a href="design-brief.html">Design Brief</a> <span id="inactive">Policy Brief</span> <a href="mapping-actors.html">Mapping Actors</a> <a href="#case-studies">Case Studies</a> <a href="#literature-surveys">Literature Surveys</a> <a href="#resources">Resources</a> <span id="report"><a href="docs/CIS_MakingVoicesHeard_Report.pdf"><i class="fas fa-arrow-circle-down"></i> Get Full Report</a></span>
      </div>
    </div>
  </div>
  <!-- Title -->
  <div class="grey">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column text">
        <h2>Voice Interfaces and Privacy</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="nine wide column text">

        <h3 id="about">Background</h3>
        <p> Efforts to develop technologies with voice recognition have been ongoing since the 1960s. Though significant advances in this field were seen in the 1990s with the advent of personal computers (PCs), the biggest breakthrough was the introduction of Siri (a voice-based virtual assistant) on the Apple iPhone in 2011. The use of voice-controlled technologies is not limited to mobile phones and smart speakers; now, they are also integrated with other smart devices such as PCs (as in the case of Microsoft’s Cortana), TVs, and cars.<sup class="superscript"><a href="#fn1">1</a></sup><a name="ref1"></a></p>
        <p>However, the increased use of voice interfaces (VIs) has led to the emergence of a host of concerns, specifically surrounding user privacy. According to a 2020 study, about 33% of adults surveyed reported that privacy concerns were a top reason for not purchasing devices with built-in VI systems; this figure saw a significant increase from 16% in 2018 and 23% in 2019.<sup class="superscript"><a href="#fn2">2</a></sup><a name="ref2"></a> This article aims to analyse the privacy concerns surrounding VIs, both now and in the future.</p>
        <h3 id="spectrum">The spectrum of VI devices</h3>
<p>The wide prevalence of microphone-enabled devices today has ushered in an “era of Ubiquitous Listening”.<sup class="superscript"><a href="#fn3">3</a></sup><a name="ref3"></a> VI devices can be categorised into three kinds – </p>

        <ul>
           <li><p><b>Manually activated devices – </b> The person presses a button that causes the device to turn on and begin recording.</li></p>
<p> </p>
           <li><p><b>Speech-activated devices – </b> These devices remain in an inert state of passive processing. The device re-records local information without transmitting or storing any information and only begins actively recording when it detects its trigger word or ‘wake word’,<sup class="superscript"><a href="#fn4">4</a></sup><a name="ref4"></a> such as ‘Hey Siri’ or ‘Ok Google’.</li></p>
<p> </p>
           <li><p><b>Always on devices – </b> These devices are designed to record and transmit data all the time until turned off.<sup class="superscript"><a href="#fn5">5</a></sup><a name="ref5"></a> </li></p>
<p> </p>
        </ul>
        </p>
<p> Privacy concerns arise, particularly, in the latter two categories, where devices can access, record, and store the data of the individual.<sup class="superscript"><a href="#fn6">6</a></sup><a name="ref6"></a> Most people do not understand when a VI is listening and where their data is being stored.<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> The data thus collected is often exploited for targeted advertising.<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a> Patent filings at the United States Patent and Trademark Office (USPTO) indicate an increase in the development of always-on devices that listen to things beyond the device’s wake word to perform increasingly sophisticated analysis.<sup class="superscript"><a href="#fn9">9</a></sup><a name="ref9"></a></p>

<h3 id="primary">Primary concerns related to privacy</h3>
<p> The same features of speech recognition that make such devices appealing are also those that give rise to privacy concerns as VIs become increasingly integrated with our daily lives.<sup class="superscript"><a href="#fn10">10</a></sup><a name="ref10"></a> Though such services typically require user permission to work, it is usually granted if people are interested in its use.<sup class="superscript"><a href="#fn11">11</a></sup><a name="ref11"></a> A survey of Android users found that only 17% of respondents paid attention to permissions during app installations and only 3% were able to answer questions on these permissions.<sup class="superscript"><a href="#fn12">12</a></sup><a name="ref12"></a> Unlike phones or devices that are used by specific individuals, VIs such as Google Home and Amazon Echo can collect data from people who have not consented to their conversation being recorded. This could include visitors, workers, and even children.</p>
<ol>
   <li><p><b>Listening in to private conversations</b> One of the main issues concerning voice-based virtual assistants is that the device can be activated through the accidental use of wake words. This constant listening has raised concerns regarding devices eavesdropping on private conversations as well as the processing and sharing of data with third parties including law enforcement agencies.<sup class="superscript"><a href="#fn13">13</a></sup><a name="ref13"></a>
</li></p>
<p>The Supreme Court of India recognised the right to privacy as implicit in the right to life and liberty under Article 21. This includes the right to be left alone. A citizen has the right to safeguard their own privacy as well as that of their family, educational details, etc. Such information can only be published with the person’s consent.<sup class="superscript"><a href="#fn14">14</a></sup><a name="ref14"></a> One of the major privacy concerns associated with the use of constantly listening VIs is that there is a high chance of third parties listening in on private conversations through the device. </p>
<p>These devices mostly record information on hearing the wake word. However, people may unintentionally cause the device to begin recording if a word similar to the wake word is spoken. A study found that more than 1,000 terms can activate VI devices, highlighting the scope of the potential risk to privacy.<sup class="superscript"><a href="#fn15">15</a></sup><a name="ref15"></a> The phrases were not just limited to those that sounded very similar to the wake words, but also remote words such as ‘unacceptable’ (to which Alexa was activated) and ‘tobacco’ (to which Echo was activated). This finding is further reiterated by the results of a study that found that VI devices were accidentally activated by 64% of people using it, in a month.<sup class="superscript"><a href="#fn16">16</a></sup><a name="ref16"></a></p>
<p>Recently, it was revealed that the big five tech companies – Amazon, Apple, Facebook, Alphabet/ Google, and Microsoft – have been using human contractors to analyse a small percentage of VI recordings. These recordings, although anonymous, can potentially contain personal information, resulting in an infringement of user rights.<sup class="superscript"><a href="#fn17">17</a></sup><a name="ref17"></a> A report also found that the information passed on included sensitive personal information such as the latitude and longitude coordinates associated with the voice data, which could indicate a person’s home address.<sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a></p>
<p> Third-party access to the personal information of individuals not only raises questions regarding privacy but also paves the way for other uses of this data such as for profiling and surveillance.</p>
<p> </p>
   <li><p><b>Access and use of VI data by law enforcement</b> Digital data has become increasingly useful to law enforcement and security agencies, with the police relying on wearables and smart devices to verify the claims of people made during an investigation.<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a> The first instance of the use of VI data as evidence was in a 2015 murder case in the United States, in which a man was found dead in a hot tub. Investigators issued a warrant to Amazon, requiring the company to turn over information and audio recordings captured by the suspect’s Echo speaker.<sup class="superscript"><a href="#fn20">20</a></sup><a name="ref20"></a> VI devices have since been used both to exonerate<sup class="superscript"><a href="#fn21">21</a></sup><a name="ref21"></a> as well as to hold suspects guilty of crimes.<sup class="superscript"><a href="#fn22">22</a></sup><a name="ref22"></a>
 <p> This risks creating a culture of state surveillance of the daily activities of citizens with potentially worrying consequences.<sup class="superscript"><a href="#fn23">23</a></sup><a name="ref23"></a> As more of such data is collected, we must ensure that it receives robust protection.<sup class="superscript"><a href="#fn24">24</a></sup><a name="ref24"></a></p>
<p> </p>
   <li><p><b>Data used for advertisement strategies</b> VI manufacturers use the data collected from people using the devices to enhance their advertisement strategies. Patents filed in the United States reveal how these devices can be used for massive information collection and intrusive digital advertising.<sup class="superscript"><a href="#fn25">25</a></sup><a name="ref25"></a> Such data is collected on the pretext of providing customers with advertisements customised to their interests.<sup class="superscript"><a href="#fn26">26</a></sup><a name="ref26"></a> VIs greatly benefit advertisers who rely on complex data sets to make essential advertising decisions. The massive amount of data gathered from app and platform VI interactions allow for efficient processing, analysis, and access of data.<sup class="superscript"><a href="#fn27">27</a></sup><a name="ref27"></a> Although the practice is currently uncommon, and manufacturers currently have policies that specifically restrict advertisements on VI devices, there is potential for their use as a mode of advertisement that informs users of content that caters to their interests.<sup class="superscript"><a href="#fn28">28</a></sup><a name="ref28"></a>
     <p> </p>
<li><p><b>The privacy of children on VI devices</b> Two-thirds of India’s internet users are in the 12–29 years age group, with those in the 12–19 age group accounting for about 21.5% of the total internet usage in metro cities.<sup class="superscript"><a href="#fn29">29</a></sup><a name="ref29"></a> Children today utilise the internet to access information, education, and other opportunities.<sup class="superscript"><a href="#fn30">30</a></sup><a name="ref30"></a> The risk to privacy is one of the primary concerns pertaining to children’s use of the internet. Children on the internet are less likely to have a comprehensive understanding of the consequences of privacy infringement, making them a vulnerable group that needs added protection.<sup class="superscript"><a href="#fn31">31</a></sup><a name="ref31"></a>
<p> Chapter IV of the Personal Data Protection Bill, 2019 (PDP), lays down special conditions for the processing of a child’s data. Such processing must be done with the intention of ensuring the best interests of the child after taking appropriate steps to verify their age and on receiving the consent of a parent or guardian.<sup class="superscript"><a href="#fn32">32</a></sup><a name="ref32"></a> The European Union’s General Data Protection Regulation (GDPR)<sup class="superscript"><a href="#fn33">33</a></sup><a name="ref33"></a> and the Children’s Online Privacy Protection Rule (COPPA)<sup class="superscript"><a href="#fn34">34</a></sup><a name="ref34"></a> in the United States also provides similar protections. These provisions have, however, not laid down explicit consequences for non-compliance with these rules; the Federal Trade Commission in the US has been slow to impose hefty fines for such acts and the still-young GDPR has not dealt extensively with such issues.<sup class="superscript"><a href="#fn35">35</a></sup><a name="ref35"></a></p>
<p> </p>
</ul>
</p>
<h3 id="biometrics">Voice biometrics and the future steps for voice technologies</h3>
<p> One of the more recent advancements in this area is the use of voice biometrics to authenticate the person using the device. Voice biometrics require that the system first process a voice sample to extract speaker-specific characteristics to build a statistical model, referred to as a voiceprint or a voice signature. Following this, any new input is compared with the existing voice signature for verification.<sup class="superscript"><a href="#fn36">36</a></sup><a name="ref36"></a> Data collected through VIs may also fall within the purview of biometric data. The Supreme Court of India, in the landmark case of Justice Puttaswamy v. Union of India, characterised biometric data as that which is intrinsically linked to humane characteristics.<sup class="superscript"><a href="#fn37">37</a></sup><a name="ref37"></a> The Personal Data Protection (PDP) Bill classifies biometric data as sensitive personal data that requires explicit consent for processing.<sup class="superscript"><a href="#fn38">38</a></sup><a name="ref38"></a></p>
<p>Voice biometrics seem to be the proposed way forward for VIs. Google has confirmed that it is working on a new Google Assistant feature that can be used to authorise financial transactions through voice biometrics.<sup class="superscript"><a href="#fn39">39</a></sup><a name="ref39"></a> Unlike identifiers such as phone numbers, address or email ids, biometrics cannot be discarded or replaced. This raises significant privacy issues relating to how such data are collected, processed, and stored. The data may be used for purposes other than that for which they were initially collected (a phenomenon also known as function creep).<sup class="superscript"><a href="#fn40">40</a></sup><a name="ref40"></a></p>
<p> Recent advancements in technology pose threats to the privacy of individuals who make use of these services. This issue becomes particularly relevant when dealing with an individual’s personal information or the information of people whose consent has not been obtained, such as children or people who are excluded from going through the privacy policies due to accessibility reasons or old age.</p>
<h3 id="conclusion">Conclusion</h3>
<p>While VIs provide not just convenience but also an easier way to navigate the internet for some people, concerns around privacy and data protection loom large. While there is a need for VIs that are better at understanding the consumer, there is also a need to understand how these systems get their training data. With more voice technologies moving to always listening systems that can send targeted ads and use voice as a verification and identification system, there is a need to look closely at the privacy risks resulting from the collection, usage, and processing of voice data.</p>


      </div>
      <div class="one wide column empty">
      </div>
      <div class="five wide column meta">
        <p><span id="grey">Research and Writing by</span> <br />Divya Pinheiro and Shweta Mohandas
          <br />
        <span id="grey">Review and Editing by</span> <br /> Saumyaa Naidu, Puthiya Purayil Sneha, <br /><span id="grey">and</span> Pranav M.B <br />
        <span id="grey">Research Inputs by</span> <br />Sumandro Chattapadhyay<br />
	       <br />
        <a href="docs/MozVoice_PolicyBrief_02.pdf"><i class="fas fa-arrow-circle-down" style="color: black;" ></i> Download Voice Interfaces and Privacy
</a></p>
        <br />
         <hr />
	       <br />
        <p><span style="line-height: 3em;">CONTENTS</span></p>
	      <p><a href="#about"><strong>Background</strong></a></p>
        <p><a href="#spectrum"><strong>The spectrum of VI devices</strong></a></p>
        <p><a href="#primary"><strong>Primary concerns related to privacy</strong></a></p>
        <p><a href="#biometrics"><strong>Voice biometrics and the future steps for voice technologies </strong></a></p>
        <p><a href="#conclusion"><strong>Conclusion</strong></a></p>

</div>

<div class="ten wide column content">
</div>
<div class="ten wide column content">
  <br />
<h3>Notes</h3>
<table class="footnote">
  <tr>

    <td class="number">1</td>
      	<td class="reference"><a name="fn1"></a>Youval Nachum, “Privacy Issues with Voice Interfaces”, <em> EEWeb, </em>1 July 2019, <a href="https://www.eeweb.com/privacy-issues-with-voice-interfaces/." target="_blank"> https://www.eeweb.com/privacy-issues-with-voice-interfaces/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref1">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">2</td>
<td class="reference"><a name="fn2"></a>Bret Kinsella, “Privacy Concerns Rise Significantly as 1-in-3 Consumers Cite It as a Reason to Avoid Smart Speakers”, <em> Voicebot.ai, </em>11 May 2020, <ahref="https://voicebot.ai/2020/05/11/privacy-concerns-rise-significantly-as-1-in-3-consumers-cite-it-as-reason-to-avoid-smart-speakers/." target="_blank"> https://voicebot.ai/2020/05/11/privacy-concerns-rise-significantly-as-1-in-3-consumers-cite-it-as-reason-to-avoid-smart-speakers/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref2">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">3</td>
<td class="reference"><a name="fn3"></a>David Talbot, “The Era of Ubiquitous Listening Dawns”, <em> MIT Technology Review, </em> 8 August 2013.<ahref="http://www.technologyreview.com/news/517801/the-era-of-ubiq-uitous-listening-dawns/. " target="_blank"> http://www.technologyreview.com/news/517801/the-era-of-ubiq-uitous-listening-dawns/. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref3">&uarr;</a></span></td>
      	</tr>

      	<tr>
      	<td class="number">4</td>
     <td class="reference"><a name="fn4"></a>Stacey Grey, <em>Always on: Privacy Implications of Microphone-Enabled Devices, </em>Future of Privacy Forum, 16 April 2016,<a href="https://fpf.org/wp-content/uploads/2016/04/FPF_Always_On_WP.pdf." target="_blank"> https://fpf.org/wp-content/uploads/2016/04/FPF_Always_On_WP.pdf.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref4">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">5</td>
      		<td class="reference"><a name="fn5"></a>Grey, Always on: Privacy Implications of Microphone-Enabled Devices.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref5">&uarr;</a></span></td>
      	</tr>

      	<tr>
      	<td class="number">6</td>
     	<td class="reference"><a name="fn6"></a>Nathan Malkin, Joe Deatrick, Allen Tong, Primal Wijesekera, Serge Egelman, David Wagner, “Privacy Attitudes of Smart Speaker Users”, <em> Proceedings on Privacy Enhancing Technologies, </em> 2019, no. 4 (2019), 250–271.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref6">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">7</td>
      	<td class="reference"><a name="fn7"></a>Nathan Malkin, Julia Bernd, Maritza Johnson, and Serge Egelman. “‘What Can’t Data Be Used For?’ Privacy Expectations about Smart TVs in the US”, <em> Proceedings of the Third European Workshop on Usable Security, </em>23 April 2018, <a href="https://www.ndss-symposium.org/wp-content/uploads/2018/06/eurousec2018_16_Malkin_paper.pdf." target="_blank">https://www.ndss-symposium.org/wp-content/uploads/2018/06/eurousec2018_16_Malkin_paper.pdf.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref7">&uarr;</a></span></td>
      	</tr>

      	<tr>
      	<td class="number">8</td>
      	<td class="reference"><a name="fn8"></a>John M. Simpson, “Home Assistant Adopter Beware: Google, Amazon Digital Assistant Patents Reveal Plans for Mass Snooping”, <em>Consumer Watchdog, </em>2017.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref8">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">9</td>
      	<td class="reference"><a name="fn9"></a>Nathan Malkin, Serge Egelman, and David Wagner, “Privacy Controls for Always-listening Devices”, <em> Proceedings of the New Security Paradigms Workshop, </em>2019, 78–91. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref9">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">10</td>
<td class="reference"><a name="fn10"></a>Stacey Grey, Always on: Privacy Implications of Microphone-Enabled Devices, <em> Future of Privacy Forum, </em>16 April 2016, <a href="https://fpf.org/wp-content/uploads/2016/04/FPF_Always_On_WP.pdf" target="_blank"> https://fpf.org/wp-content/uploads/2016/04/FPF_Always_On_WP.pdf </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref10">&uarr;</a></span></td>

      	</tr>
<tr>
          	<td class="number">11</td>
       	<td class="reference"><a name="fn11"></a>Dan Arp, Erwin Quiring, Christian Wressnegger, and K. Rieck, “Privacy Threats through Ultrasonic Side Channels on Mobile Devices”, 2017 <em> IEEE European Symposium on Security and Privacy, </em>2017, pp. 35–4.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref11">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">12</td>
<td class="reference"><a name="fn12"></a>Adrienne Porter Felt, Elizabeth Ha, Serge Egelman, Ariel Haney, Erika Chin, and David Wagner, “Android Permissions: User Attention, Comprehension, and Behaviour”, in <em> Proceedings of the Eighth Symposium on Usable Privacy and Security (SOUPS 2012) </em> (ACM Press, 2012)..&nbsp;&nbsp;<span class="internal-nav"><a href="#ref12">&uarr;</a></span></td>

      	</tr>
<tr>
          	<td class="number">13</td>
      	<td class="reference"><a name="fn13"></a>Sidney Fussell, “Police Want Your Smart Speaker—Here’s Why”, <em> Wired, </em> 23 August 2020, <ahref="https://www.wired.com/story/star-witness-your-smart-speaker/." target="_blank"> https://www.wired.com/story/star-witness-your-smart-speaker/./a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref13">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">14</td>
      	<td class="reference"><a name="fn14"></a> <em> R Rajagopal v. State of T.N. </em> (1994) 6 SCC 632, pp. 649–51.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref14">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">15</td>
      	<td class="reference"><a name="fn15"></a>Eric Hal Schwartz, “More than 1,000 Phrases Will Accidentally Awaken Alexa, Siri, and Google Assistant: Study”, <em> Voicebot.ai, </em>6 July 2020, <a href="https://voicebot.ai/2020/07/06/more-than-1000-phrases-will-accidentally-awaken-alexa-siri-and-google-assistant-study/." target="_blank"> https://voicebot.ai/2020/07/06/more-than-1000-phrases-will-accidentally-awaken-alexa-siri-and-google-assistant-study/. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref15">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">16</td>
     <td class="reference"><a name="fn16"></a>Eric Hal Schwartz, “Voice Assistants Accidentally Awakened by 64% of Users a Month: Survey”,  <em> Voicebot.ai, </em> 9 January 2020, <a href="https://voicebot.ai/2020/01/09/voice-assistants-accidentally-awakened-by-64-of-users-a-month-survey/.  "target="_blank">https://voicebot.ai/2020/01/09/voice-assistants-accidentally-awakened-by-64-of-users-a-month-survey/. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref16">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">17</td>
      	<td class="reference"><a name="fn17"></a>Dorian Lynskey, “‘Alexa, Are You Invading My Privacy?’ – The Dark Side of Our Voice Assistants”, <em> The Guardian, </em>9 October 2019, <a href=”https://www.theguardian.com/technology/2019/oct/09/alexa-are-you-invading-my-privacy-the-dark-side-of-our-voice-assistants "target="_blank">https://www.theguardian.com/technology/2019/oct/09/alexa-are-you-invading-my-privacy-the-dark-side-of-our-voice-assistants</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref17">&uarr;</a></span></td>
      	</tr>
 <tr>
      	<td class="number">18</td>
<td class="reference"><a name="fn18"></a>Sarah Perez, “41% of Voice Assistant Users Have Concerns about Trust and Privacy, Report Finds”, <em> TechCrunch, </em>25 April 2019,<ahref=”https://techcrunch.com/2019/04/24/41-of-voice-assistant-users-have-concerns-about-trust-and-privacy-report-finds/."target="_blank">https://techcrunch.com/2019/04/24/41-of-voice-assistant-users-have-concerns-about-trust-and-privacy-report-finds/. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref18">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">19</td>
      	   	<td class="reference"><a name="fn19"></a>Fussell, “Police Want Your Smart Speaker”, <em> Wired. </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref19">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">20</td>
      	<td class="reference"><a name="fn20"></a>“Servant or Spy? Law Enforcement, Privacy Advocates Grapple with Brave New World of AI Assistants”, <em> CNBC, </em> accessed 24 November 2021,<a href="https://www.cnbc.com/2017/01/06/servant-or-spy-law-enforcement-privacy-advocates-grapple-with-brave-new-world-of-ai-assistants.html." target="_blank"> https://www.cnbc.com/2017/01/06/servant-or-spy-law-enforcement-privacy-advocates-grapple-with-brave-new-world-of-ai-assistants.html.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref20">&uarr;</a></span></td>

      	</tr>
<tr>
          	<td class="number">21</td>
      	<td class="reference"><a name="fn21"></a>Kayla Epstein, “Police Think Amazon's Alexa May Have Information on a Fatal Stabbing Case”, <em> Washington Post, </em> 3 November 2019,<ahref="https://www.washingtonpost.com/technology/2019/11/02/police-think-amazons-alexa-may-have-information-fatal-stabbing-case/"target="_blank">https://www.washingtonpost.com/technology/2019/11/02/police-think-amazons-alexa-may-have-information-fatal-stabbing-case/ </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref21">&uarr;</a></span></td>
      	</tr>

      	<tr>
      	<td class="number">22</td>
      	<td class="reference"><a name="fn22"></a>Juang,"Servant or Spy?", <em> CNBC </em>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref22">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">23</td>
      	<td class="reference"><a name="fn23"></a>Garfield Benjamin, “Amazon Echo's Privacy Issues Go Way Beyond Voice Recordings”, <em> The Conversation, </em>21 January 2020, <a href="https://theconversation.com/amazon-echos-privacy-issues-go-way-beyond-voice-recordings-130016.  target="_blank">https://theconversation.com/amazon-echos-privacy-issues-go-way-beyond-voice-recordings-130016.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref23">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">24</td>

<td class="reference"><a name="fn25"></a>Joseph Jerome, “Alexa, Is Law Enforcement Listening?”  <em> Center for Democracy and Technology, </em> 4 January 2017, <a href="https://cdt.org/insights/alexa-is-law-enforcement-listening/.target="_blank"> https://cdt.org/insights/alexa-is-law-enforcement-listening/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref24">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">25</td>
      	<td class="reference"><a name="fn25"></a>John M. Simpson, “Home Assistant Adopter Beware: Google, Amazon Digital Assistant Patents Reveal Plans for Mass Snooping”, <em> Consumer Watchdog, </em>13 December 2017, <ahref="https://www.consumerwatchdog.org/privacy-technology/home-assistant-adopter-beware-google-amazon-digital-assistant-patents-reveal." target="_blank"> https://www.consumerwatchdog.org/privacy-technology/home-assistant-adopter-beware-google-amazon-digital-assistant-patents-reveal. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref25">&uarr;</a></span></td>
      	</tr>

      	<tr>
      	<td class="number">26</td>
      	<td class="reference"><a name="fn26"></a>Simpson, “ Home Assistant Adopter Beware”, <em> Consumer Watchdog </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref26">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">27</td>
      	<td class="reference"><a name="fn27"></a>Jason Hall, “How Artificial Intelligence is Transforming Digital Marketing”, <em> Forbes, </em> accessed 24 November 2021,<ahref="https://www.forbes.com/sites/forbesagencycouncil/2019/08/21/how-artificial-intelligence-is-transforming-digital-marketing/?sh=39700bde21e1." target="_blank"> https://www.forbes.com/sites/forbesagencycouncil/2019/08/21/how-artificial-intelligence-is-transforming-digital-marketing/?sh=39700bde21e1. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref27">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">28</td>
   <td class="reference"><a name="fn28"></a>Jesus Martín, “Advertising in Voice Interfaces”, <em> UX Collective, </em>14 July 2020,<ahref="https://uxdesign.cc/advertising-in-voice-interfaces-4b1ca14fa28b " target="_blank"> https://uxdesign.cc/advertising-in-voice-interfaces-4b1ca14fa28b </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref28">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">29</td>
      	<td class="reference"><a name="fn29"></a>Neilsen, “Digital in India 2019 – Round 2 Report”, <em> IAMAI, </em> accessed 24 November 2021, <ahref="https://reverieinc.com/wp-content/uploads/2020/09/IAMAI-Digital-in-India-2019-Round-2-Report.pdf." target="_blank"> https://reverieinc.com/wp-content/uploads/2020/09/IAMAI-Digital-in-India-2019-Round-2-Report.pdf. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref29">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">30</td>
      <td class="reference"><a name="fn30"></a>UNICEF, “The State of the World's Children 2017. Children in a Digital World”, 2017, <ahref="https://www.unicef.org/publications/files/SOWC_2017_ENG_WEB.pdf " target="_blank"> https://www.unicef.org/publications/files/SOWC_2017_ENG_WEB.pdf /a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref30">&uarr;</a></span></td>

      	</tr>
<tr>
          	<td class="number">31</td>
      	<td class="reference"><a name="fn31"></a>Sonia Livingstone, “Children: A Special Case for Privacy?” <em> International Institute of Communications, </em>19 December 2019 <a href=" http://www.iicom.org/intermedia/intermedia-july-2018/children-a-special-case-for-privay" target="_blank">  http://www.iicom.org/intermedia/intermedia-july-2018/children-a-special-case-for-privay</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">32</td>
      	<td class="reference"><a name="fn32"></a>Section 16, Personal Data Protection Bill, 2019.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref32">&uarr;</a></span></td>
      	</tr>
<tr>
          	<td class="number">33</td>
      	<td class="reference"><a name="fn33"></a>General Data Protection Regulation (GDPR),<a href=”https://gdpr-info.eu/.”arget="_blank"> https://gdpr-info.eu/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</a></span></td>
      	</tr>
      	<tr>
      	<td class="number">34</td>
<td class="reference"><a name="fn34"></a>Federal Trade Commission, “Children’s Online Privacy Protection Rule”, <a href=" https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule" target="_blank">https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref34">&uarr;</a></span></td>

      	</tr>
<tr>
      	<td class="number">35</td>
<td class="reference"><a name="fn35"></a>Martyn Farrows, “Let's Talk Voice Tech, Data Privacy, and Kids”, <em> VoiceBot.AI, </em>28 March 2020, <ahref="https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/."https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/ "target="_blank">https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/."https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/ </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref35">&uarr;</a></span></td>
      	</tr>
<tr>
      	<td class="number">36</td>
<td class="reference"><a name="fn36"></a>Abhijit Ahaskar, “Voice Biometrics Are Cleverer Now, But Still Need More Work”, <em> LiveMint, </em> 6 February 2020, <ahref="https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/."https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/."target="_blank">https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/."https://voicebot.ai/2020/03/28/lets-talk-voice-tech-data-privacy-and-kids/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref36">&uarr;</a></span></td>
      	</tr>
<tr>
      	<td class="number">37</td>
      	<td class="reference"><a name="fn37"></a><em> K.S. Puttaswamy v. Union of India </em>(2017) 10 SCC 1.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref37">&uarr;</a></span></td>
      	</tr>
<tr>
      	<td class="number">38</td>
      	<td class="reference"><a name="fn38"></a>Section 3(7), (Draft) Personal Data Protection Bill, 2019.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref38">&uarr;</a></span></td>
      	</tr>
<tr>
      	<td class="number">39</td>
<td class="reference"><a name="fn39"></a>Ryne Hager, “Google Confirms New Voice Confirmation Feature for Purchases in Assistant”, <em> Android Police, </em>25 May 2020,<ahref="https://www.androidpolice.com/2020/05/25/google-assistant-gets-new-confirm-with-voice-match-setting-for-payments/."target="_blank">https://www.androidpolice.com/2020/05/25/google-assistant-gets-new-confirm-with-voice-match-setting-for-payments/. </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref39">&uarr;</a></span></td>
      	</tr>
<tr>
      	<td class="number">40</td>
<td class="reference"><a name="fn40"></a>Digidentity. “Privacy or Security? ‘Function Creep’ Kills Your Privacy”, retrieved October 17, 2020, <ahref="https://www.digidentity.eu/en/article/Function-creep-kills-your-privacy/ ."target="_blank">https://www.digidentity.eu/en/article/Function-creep-kills-your-privacy/ </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref40">&uarr;</a></span></td>



</tr>
</table>
    </div>
  </div>

      <div class="six wide column empty">
      </div>


    </div>
  </div>
  <!-- Footer -->
  <div class="footer">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="five wide column">
        <h3>About the Study</h3>
        <p>We believe that voice interfaces have the potential to democratise the use of the internet by addressing limitations related to reading and writing on digital text-only platforms and devices. This report examines the current landscape of voice interfaces in India, with a focus on concerns related to privacy and data protection, linguistic barriers, and accessibility for persons with disabilities (PwDs). This project was undertaken with support by the Mozilla Corporation.</p>
      </div>
      <div class="five wide column">
        <h3>Research Team</h3>
        <p>Research: Shweta Mohandas, Saumyaa Naidu, Deepika NS, Divya Pinheiro, Sweta Bisht </p>
        <p><em>Conceptualisation, Planning, and Research Inputs</em> Sumandro Chattapadhyay, Puthiya Purayil Sneha</p>
        <p><em>Illustration</em> Kruthika NS</p>
        <p><em>Website Design</em> Saumyaa Naidu</p>
        <p><em>Website Development</em> Sumandro Chattapadhyay, Pranav M Bidare</p>
        <p><em>Review and Editing</em> Puthiya Purayil Sneha, Divyank Katira, Pranav M Bidare, Torsha Sarkar, Pallavi Bedi, Divya Pinheiro</p>
        <p><em>Copy Editing</em> The Clean Copy</p>
      </div>
      <div class="four wide column">
        <h3>Copyright and Credits</h3>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2021<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a><br/><a href="https://fonts.google.com/specimen/Barlow" target="_blank">Barlow</a> and <a href="https://fonts.google.com/specimen/Open+Sans" target="_blank">Open Sans</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/cis-india/mozvoice" target="_blank">GitHub</a></p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="sixteen wide column">
        <div style="float: center; clear: both;">
        <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons" style="float: center; clear: both;">
          <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
	</div>
      </div>
    </div>
  </div>
</body>
</html>
