<!DOCTYPE html>
<html><!DOCTYPE html>
<html>
<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Making Voices Heard | A study by the Centre for Internet and Society, India, supported by Mozilla Corporation" />
  <!-- Title + CSS + Favicon -->
  <title>Making Voices Heard</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Header -->
  <div>
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <!-- Top Navigation Bar -->
  <div class="blue nav">
    <div class="ui container">
      <div class="nav-entries">
        <a href="index.html" id="home">Home</a> <a href="design-brief.html">Design Brief</a> <span id="inactive">Policy Brief</span> <a href="mapping-actors.html">Mapping Actors</a> <a href="#case-studies">Case Studies</a> <a href="#literature-surveys">Literature Surveys</a> <a href="#resources">Resources</a> <span id="report"><a href="docs/CIS_MakingVoicesHeard_Report.pdf"><i class="fas fa-arrow-circle-down"></i> Get Full Report</a></span>
      </div>
    </div>
  </div>
  <!-- Title -->
  <div class="grey">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="fourteen wide column text">
        <h2>Voice Interfaces and Privacy</h2>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="one wide column empty">
      </div>
      <div class="nine wide column text">

        <h3 id="about">Background</h3>
        <p> Efforts to develop technologies with voice recognition have been ongoing since the 1960s. Though significant advances in this field were seen in the 1990s with the advent of personal computers (PCs), the biggest breakthrough was the introduction of Siri (a voice-based virtual assistant) on the Apple iPhone in 2011. The use of voice-controlled technologies is not limited to mobile phones and smart speakers; now, they are also integrated with other smart devices such as PCs (as in the case of Microsoft’s Cortana), TVs, and cars.<sup class="superscript"><a href="#fn1">1</a></sup><a name="ref1"></a></p>
        <p>However, the increased use of voice interfaces (VIs) has led to the emergence of a host of concerns, specifically surrounding user privacy. According to a 2020 study, about 33% of adults surveyed reported that privacy concerns were a top reason for not purchasing devices with built-in VI systems; this figure saw a significant increase from 16% in 2018 and 23% in 2019.<sup class="superscript"><a href="#fn2">2</a></sup><a name="ref2"></a> This article aims to analyse the privacy concerns surrounding VIs, both now and in the future.</p>
        <h3 id="spectrum">The spectrum of VI devices</h3>
<p>The wide prevalence of microphone-enabled devices today has ushered in an “era of Ubiquitous Listening”.<sup class="superscript"><a href="#fn3">3</a></sup><a name="ref3"></a> VI devices can be categorised into three kinds – </p>

        <ul>
           <li><p><b>Manually activated devices – </b> The person presses a button that causes the device to turn on and begin recording.</li></p>
<p> </p>
           <li><p><b>Speech-activated devices – </b> These devices remain in an inert state of passive processing. The device re-records local information without transmitting or storing any information and only begins actively recording when it detects its trigger word or ‘wake word’,<sup class="superscript"><a href="#fn4">4</a></sup><a name="ref4"></a> such as ‘Hey Siri’ or ‘Ok Google’.</li></p>
<p> </p>
           <li><p><b>Always on devices – </b> These devices are designed to record and transmit data all the time until turned off.<sup class="superscript"><a href="#fn5">5</a></sup><a name="ref5"></a> </li></p>
<p> </p>
        </ul>
        </p>
<p> Privacy concerns arise, particularly, in the latter two categories, where devices can access, record, and store the data of the individual.<sup class="superscript"><a href="#fn6">6</a></sup><a name="ref6"></a> Most people do not understand when a VI is listening and where their data is being stored.<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> The data thus collected is often exploited for targeted advertising.<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a> Patent filings at the United States Patent and Trademark Office (USPTO) indicate an increase in the development of always-on devices that listen to things beyond the device’s wake word to perform increasingly sophisticated analysis.<sup class="superscript"><a href="#fn9">9</a></sup><a name="ref9"></a></p>

<h3 id="primary">Primary concerns related to privacy</h3>
<p> The same features of speech recognition that make such devices appealing are also those that give rise to privacy concerns as VIs become increasingly integrated with our daily lives.<sup class="superscript"><a href="#fn10">10</a></sup><a name="ref10"></a> Though such services typically require user permission to work, it is usually granted if people are interested in its use.<sup class="superscript"><a href="#fn11">11</a></sup><a name="ref11"></a> A survey of Android users found that only 17% of respondents paid attention to permissions during app installations and only 3% were able to answer questions on these permissions.<sup class="superscript"><a href="#fn12">12</a></sup><a name="ref12"></a> Unlike phones or devices that are used by specific individuals, VIs such as Google Home and Amazon Echo can collect data from people who have not consented to their conversation being recorded. This could include visitors, workers, and even children.</p>
<ol>
   <li><p><b>Listening in to private conversations</b> One of the main issues concerning voice-based virtual assistants is that the device can be activated through the accidental use of wake words. This constant listening has raised concerns regarding devices eavesdropping on private conversations as well as the processing and sharing of data with third parties including law enforcement agencies.<sup class="superscript"><a href="#fn13">13</a></sup><a name="ref13"></a>
</li></p>
<p>The Supreme Court of India recognised the right to privacy as implicit in the right to life and liberty under Article 21. This includes the right to be left alone. A citizen has the right to safeguard their own privacy as well as that of their family, educational details, etc. Such information can only be published with the person’s consent.<sup class="superscript"><a href="#fn14">14</a></sup><a name="ref14"></a> One of the major privacy concerns associated with the use of constantly listening VIs is that there is a high chance of third parties listening in on private conversations through the device. </p>
<p>These devices mostly record information on hearing the wake word. However, people may unintentionally cause the device to begin recording if a word similar to the wake word is spoken. A study found that more than 1,000 terms can activate VI devices, highlighting the scope of the potential risk to privacy.<sup class="superscript"><a href="#fn15">15</a></sup><a name="ref15"></a> The phrases were not just limited to those that sounded very similar to the wake words, but also remote words such as ‘unacceptable’ (to which Alexa was activated) and ‘tobacco’ (to which Echo was activated). This finding is further reiterated by the results of a study that found that VI devices were accidentally activated by 64% of people using it, in a month.<sup class="superscript"><a href="#fn16">16</a></sup><a name="ref16"></a></p>
<p>Recently, it was revealed that the big five tech companies – Amazon, Apple, Facebook, Alphabet/ Google, and Microsoft – have been using human contractors to analyse a small percentage of VI recordings. These recordings, although anonymous, can potentially contain personal information, resulting in an infringement of user rights.<sup class="superscript"><a href="#fn17">17</a></sup><a name="ref17"></a> A report also found that the information passed on included sensitive personal information such as the latitude and longitude coordinates associated with the voice data, which could indicate a person’s home address.<sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a></p>
<p> Third-party access to the personal information of individuals not only raises questions regarding privacy but also paves the way for other uses of this data such as for profiling and surveillance.</p>
<p> </p>
   <li><p><b>Access and use of VI data by law enforcement</b> Digital data has become increasingly useful to law enforcement and security agencies, with the police relying on wearables and smart devices to verify the claims of people made during an investigation.<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a> The first instance of the use of VI data as evidence was in a 2015 murder case in the United States, in which a man was found dead in a hot tub. Investigators issued a warrant to Amazon, requiring the company to turn over information and audio recordings captured by the suspect’s Echo speaker.<sup class="superscript"><a href="#fn20">20</a></sup><a name="ref20"></a> VI devices have since been used both to exonerate<sup class="superscript"><a href="#fn21">21</a></sup><a name="ref21"></a> as well as to hold suspects guilty of crimes.<sup class="superscript"><a href="#fn22">22</a></sup><a name="ref22"></a>
 <p> This risks creating a culture of state surveillance of the daily activities of citizens with potentially worrying consequences.<sup class="superscript"><a href="#fn23">23</a></sup><a name="ref23"></a> As more of such data is collected, we must ensure that it receives robust protection.<sup class="superscript"><a href="#fn24">24</a></sup><a name="ref24"></a></p>
<p> </p>
   <li><p><b>Data used for advertisement strategies</b> VI manufacturers use the data collected from people using the devices to enhance their advertisement strategies. Patents filed in the United States reveal how these devices can be used for massive information collection and intrusive digital advertising.<sup class="superscript"><a href="#fn25">25</a></sup><a name="ref25"></a> Such data is collected on the pretext of providing customers with advertisements customised to their interests.<sup class="superscript"><a href="#fn26">26</a></sup><a name="ref26"></a> VIs greatly benefit advertisers who rely on complex data sets to make essential advertising decisions. The massive amount of data gathered from app and platform VI interactions allow for efficient processing, analysis, and access of data.<sup class="superscript"><a href="#fn27">27</a></sup><a name="ref27"></a> Although the practice is currently uncommon, and manufacturers currently have policies that specifically restrict advertisements on VI devices, there is potential for their use as a mode of advertisement that informs users of content that caters to their interests.<sup class="superscript"><a href="#fn28">28</a></sup><a name="ref28"></a>
     <p> </p>
<li><p><b>The privacy of children on VI devices</b> Two-thirds of India’s internet users are in the 12–29 years age group, with those in the 12–19 age group accounting for about 21.5% of the total internet usage in metro cities.<sup class="superscript"><a href="#fn29">29</a></sup><a name="ref29"></a> Children today utilise the internet to access information, education, and other opportunities.<sup class="superscript"><a href="#fn30">30</a></sup><a name="ref30"></a> The risk to privacy is one of the primary concerns pertaining to children’s use of the internet. Children on the internet are less likely to have a comprehensive understanding of the consequences of privacy infringement, making them a vulnerable group that needs added protection.<sup class="superscript"><a href="#fn31">31</a></sup><a name="ref31"></a>
<p> Chapter IV of the Personal Data Protection Bill, 2019 (PDP), lays down special conditions for the processing of a child’s data. Such processing must be done with the intention of ensuring the best interests of the child after taking appropriate steps to verify their age and on receiving the consent of a parent or guardian.<sup class="superscript"><a href="#fn32">32</a></sup><a name="ref32"></a> The European Union’s General Data Protection Regulation (GDPR)<sup class="superscript"><a href="#fn33">33</a></sup><a name="ref33"></a> and the Children’s Online Privacy Protection Rule (COPPA)<sup class="superscript"><a href="#fn34">34</a></sup><a name="ref34"></a> in the United States also provides similar protections. These provisions have, however, not laid down explicit consequences for non-compliance with these rules; the Federal Trade Commission in the US has been slow to impose hefty fines for such acts and the still-young GDPR has not dealt extensively with such issues.<sup class="superscript"><a href="#fn35">35</a></sup><a name="ref35"></a></p>
<p> </p>
</ul>
</p>
<h3 id="biometrics">Voice biometrics and the future steps for voice technologies</h3>
<p> One of the more recent advancements in this area is the use of voice biometrics to authenticate the person using the device. Voice biometrics require that the system first process a voice sample to extract speaker-specific characteristics to build a statistical model, referred to as a voiceprint or a voice signature. Following this, any new input is compared with the existing voice signature for verification.<sup class="superscript"><a href="#fn36">36</a></sup><a name="ref36"></a> Data collected through VIs may also fall within the purview of biometric data. The Supreme Court of India, in the landmark case of Justice Puttaswamy v. Union of India, characterised biometric data as that which is intrinsically linked to humane characteristics.<sup class="superscript"><a href="#fn37">37</a></sup><a name="ref37"></a> The Personal Data Protection (PDP) Bill classifies biometric data as sensitive personal data that requires explicit consent for processing.<sup class="superscript"><a href="#fn38">38</a></sup><a name="ref38"></a></p>
<p>Voice biometrics seem to be the proposed way forward for VIs. Google has confirmed that it is working on a new Google Assistant feature that can be used to authorise financial transactions through voice biometrics.<sup class="superscript"><a href="#fn39">39</a></sup><a name="ref39"></a> Unlike identifiers such as phone numbers, address or email ids, biometrics cannot be discarded or replaced. This raises significant privacy issues relating to how such data are collected, processed, and stored. The data may be used for purposes other than that for which they were initially collected (a phenomenon also known as function creep).<sup class="superscript"><a href="#fn40">40</a></sup><a name="ref40"></a></p>
<p> Recent advancements in technology pose threats to the privacy of individuals who make use of these services. This issue becomes particularly relevant when dealing with an individual’s personal information or the information of people whose consent has not been obtained, such as children or people who are excluded from going through the privacy policies due to accessibility reasons or old age.</p>
<h3 id="conclusion">Conclusion</h3>
<p>While VIs provide not just convenience but also an easier way to navigate the internet for some people, concerns around privacy and data protection loom large. While there is a need for VIs that are better at understanding the consumer, there is also a need to understand how these systems get their training data. With more voice technologies moving to always listening systems that can send targeted ads and use voice as a verification and identification system, there is a need to look closely at the privacy risks resulting from the collection, usage, and processing of voice data.</p>


      </div>
      <div class="one wide column empty">
      </div>
      <div class="five wide column meta">
        <p><span id="grey">Research and Writing by</span> <br />Divya Pinheiro and Shweta Mohandas
          <br />
        <span id="grey">Review and Editing by</span> <br /> Saumyaa Naidu, Puthiya Purayil Sneha, <br /><span id="grey">and</span> Pranav M.B <br />
        <span id="grey">Research Inputs by</span> <br />Sumandro Chattapadhyay<br />
	       <br />
        <a href="docs/MozVoice_PolicyBrief_02.pdf"><i class="fas fa-arrow-circle-down" style="color: black;" ></i> Download Voice Interfaces and Privacy
</a></p>
        <br />
         <hr />
	       <br />
        <p><span style="line-height: 3em;">CONTENTS</span></p>
	      <p><a href="#about"><strong>Background</strong></a></p>
        <p><a href="#spectrum"><strong>The spectrum of VI devices</strong></a></p>
        <p><a href="#primary"><strong>Primary concerns related to privacy</strong></a></p>
        <p><a href="#biometrics"><strong>Voice biometrics and the future steps for voice technologies </strong></a></p>
        <p><a href="#conclusion"><strong>Conclusion</strong></a></p>

</div>

<div class="ten wide column content">
</div>
<div class="ten wide column content">
  <br />
<h3>Notes</h3>
<table class="footnote">
  <tr>

    <td class="number">1</td>

    <td class="reference"><a name="fn1"></a>“Voice Interfaces”, <em> Infosys </em>, 2019, accessed 3 November 2021<ahref="https://www.infosys.com/services/incubating-emerging-technologies/offerings/Documents/voice-interfaces.pdf."target="_blank">https://www.infosys.com/services/incubating-emerging-technologies/offerings/Documents/voice-interfaces.pdf.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref1">&uarr;</a></span></td>
        	</tr>

        	<tr>
        	<td class="number">2</td>

        	<td class="reference"><a name="fn2"></a>Rudnicky, A. I., “The Design of Voice-driven Interfaces”, In <em>Proceedings of the Workshop on Speech and Natural Language, </em>(Association for Computational Linguistics, USA, 1989), 120–124.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref2">&uarr;</a></span></td>
        	</tr>

      	<tr>
        	<td class="number">3</td>
  	<td class="reference"><a name="fn3"></a>Rudnicky, A. I., <em> “The Design of Voice-driven Interfaces”, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref3">&uarr;</a></span></td>

        	</tr>

  	<tr>
  <td class="number">4</td>
  <td class="reference"><a name="fn4"></a>Cole, R., et al., “The Challenge of Spoken Language Systems: Research Directions for the Nineties”, <em>IEEE Transactions on Speech and Audio Processing, </em> 3, no. 1 (1995): 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref4">&uarr;</a></span></td>
  	</tr>

               <tr>
  <td class="number">5</td>
    <td class="reference"><a name="fn5"></a>Ayesha Pervaiz, et al., “Incorporating Noise Robustness in Speech Command Recognition by Noise Augmentation of Training Data”, <em> Sensors 20 </em>, no. 8 (2020): 2336–2337,<ahref="https://doi.org/10.3390/s20082326."target="_blank">https://doi.org/10.3390/s20082326.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref5">&uarr;</a></span></td>

  	</tr>
        	<tr>
  <td class="number">6</td>
  <td class="reference"><a name="fn6"></a>Cole, R., et al., “The Challenge of Spoken Language Systems: Research Directions for the Nineties”, <em>IEEE Transactions on Speech and Audio Processing, </em> 3, no. 1 (1995): 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref6">&uarr;</a></span></td>
  	</tr>
        	<tr>
        	<td class="number">7</td>
        	<td class="reference"><a name="fn7"></a>Cole, R., et al., “The Challenge of Spoken Language Systems: Research Directions for the Nineties”, <em>IEEE Transactions on Speech and Audio Processing, </em> 3, no. 1 (1995): 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref7">&uarr;</a></span></td>

  	</tr>
        	<tr>
        	<td class="number">8</td>
        		<td class="reference"><a name="fn8"></a>Rudnicky, A. I., <em> “The Design of Voice-driven Interfaces”, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref8">&uarr;</a></span></td>

        	</tr>
               <tr>
    	<td class="number">9</td>
  <td class="reference"><a name="fn9"></a>Dyches, H., Alemagno, S., Llorens, S. A., and Butts, J. M., “Automated Telephone-Administered Substance Abuse Screening for Adults in Primary Care”, <em>Health Care Management Science, </em> 2, no. 4 (1999): 199–204 <a href="doi:10.1023/a:1019000231214." target="_blank">doi:10.1023/a:1019000231214.  </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref9">&uarr;</a></span></td>

      	</tr>
          	<tr>
  	<td class="number">10</td>
  <td class="reference"><a name="fn10"></a>“Usage Statistics of Content Languages for Websites”, <em> W3Techs, </em> accessed 3 November 2021 <a href="https://w3techs.com/technologies/overview/content_language."target="_blank">https://w3techs.com/technologies/overview/content_language.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref10">&uarr;</a></span></td>
  	</tr>
                <tr>
        	<td class="number">11</td>
        	<td class="reference"><a name="fn11"></a>Noack, R., “The Future of Language”, <em> Washington Post, </em> September 25,2015,<a href="https://www.washingtonpost.com/news/worldviews/wp/2015/09/24/the-future-of-language/."target="_blank">https://www.washingtonpost.com/news/worldviews/wp/2015/09/24/the-future-of-language/."</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref11">&uarr;</a></span></td>

        	</tr>
        	<tr>
        	<td class="number">12</td>

     <td class="reference"><a name="fn12"></a>The terms ‘native language’ and ‘native speaker’ are used here in the specific context of the report cited. As socio-cultural constructs, the terms have been a source of debate, particularly in postcolonial contexts and in the field of linguistics, and more recently in efforts related to language revitalisation. For more on this see: Davies, Alan. The Native Speaker: Myth and Reality. Multilingual Matters, 2003 and  O’Rourke, Bernadette. “New Speakers of Minority Languages.” <em>The Routledge Handbook of Language Revitalization,</em> 2018, 265–73.<a href=" https://doi.org/10.4324/9781315561271-33."target="_blank">https://doi.org/10.4324/9781315561271-33.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref12">&uarr;</a></span></td>


        	</tr>
        	<tr>
        	<td class="number">13</td>
  	<td class="reference"><a name="fn13"></a>Noack, R., “The Future of Language ”, <em> Washington Post. </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref13">&uarr;</a></span></td>
        	</tr>
              <tr>
  <td class="number">14</td>
  <td class="reference"><a name="fn14"></a>Noack, R., “Usage Statistics of Content Languages for Websites”, <em> W3Techs, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref14">&uarr;</a></span></td>


  	</tr>
    <tr>
  <td class="number">15</td>
  <td class="reference"><a name="fn15"></a>Cole,“The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref15">&uarr;</a></span></td>
        </tr>
              <tr>
  <td class="number">16</td>
        	<td class="reference"><a name="fn16"></a>Cole,“The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref16">&uarr;</a></span></td>

        	</tr>
  <tr>
        	<td class="number">17</td>
<td class="reference"><a name="fn17"></a>Freitas, J., et al., “Spoken Language Interface for Mobile Devices”,  in Human Language Technology. Challenges of the Information Society, </em> eds. Zygmunt Vetulani, Hans Uszkoreit (Springer, Berlin, Heidelberg, 2009), 25–35. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref17">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">18</td>
  <td class="reference"><a name="fn18"></a>“RecognizedPhrase.Confidence Property”, Microsoft, accessed 17 November 2021,<a href=" https://docs.microsoft.com/en-us/dotnet/api/system.speech.recognition.recognizedphrase.confidence?view=netframework-4.8.target="_blank”>https://docs.microsoft.com/en-us/dotnet/api/system.speech.recognition.recognizedphrase.confidence?view=netframework-4.8.</a>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref18">&uarr;</a></span></td>
        	</tr>
  <tr>
            	<td class="number">19</td>
              	<td class="reference"><a name="fn19"></a>Cole, “The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref19">&uarr;</a></span></td>
        	</tr>
        	<tr>
        	<td class="number">20</td>
  	<td class="reference"><a name="fn20"></a>Cole, “The Challenge of Spoken Language Systems”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref20">&uarr;</a></span></td>
        	</tr>

      	<tr>
        	<td class="number">21</td>
  <td class="reference"><a name="fn21"></a>The Information Technology Act, 2000.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref21">&uarr;</a></span></td>

        	</tr>
  	<tr>
  <td class="number">22</td>
  <td class="reference"><a name="fn22"></a>Hernandez, Daniela, “How Voice Recognition Systems Discriminate Against People with Accents: When Will There be Speech Recognition for the Rest of Us?”, <em> Splinter </em> , 21 August 2015,<a href="https://splinternews.com/how-voice-recognition-systems-discriminate-against-peop-1793850122."target="_blank">https://splinternews.com/how-voice-recognition-systems-discriminate-against-peop-1793850122.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref22">&uarr;</a></span></td>
  	</tr>
               <tr>
  <td class="number">23</td>
  <td class="reference"><a name="fn23"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref23">&uarr;</a></span></td>
  	</tr>
        	<tr>
  <td class="number">24</td>
  <td class="reference"><a name="fn24"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref24">&uarr;</a></span></td>
  	</tr>
        	<tr>
  <td class="number">25</td>
        	<td class="reference"><a name="fn25"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref25">&uarr;</a></span></td>
        	</tr>
        	<tr>
        	<td class="number">26</td>
        	<td class="reference"><a name="fn26"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref26">&uarr;</a></span></td>

        	</tr>
               <tr>
    	<td class="number">27</td>
  <td class="reference"><a name="fn27"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref27">&uarr;</a></span></td>
      	</tr>
          	<tr>
  	<td class="number">28</td>
  <td class="reference"><a name="fn28"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref28">&uarr;</a></span></td>
  	</tr>
                <tr>
        	<td class="number">29</td>
        	<td class="reference"><a name="fn29"></a> Hernandez, “How Voice Recognition Systems” <em> Splinter </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref29">&uarr;</a></span></td>
     	</tr>
        	<tr>
        	<td class="number">30</td>
  <td class="reference"><a name="fn30"></a>Walkley, A. and Nagpal, J. “Why Hindi Matters in the Digital Age”,  <em> Think with Google, </em> 2015, from<ahref=”https://www.thinkwithgoogle.com/intl/en-apac/trends-and-insights/hindi-matters-digital-age/.”target="_blank”>https://www.thinkwithgoogle.com/intl/en-apac/trends-and-insights/hindi-matters-digital-age/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</a></span></td>
        	      	<tr>
        	<td class="number">31</td>
  <td class="reference"><a name="fn31"></a>Sanchez-Stockhammer, Christina, “Hybridization in Language”, In <em> Conceptualizing Cultural Hybridization: A Transdisciplinary Approach, </em> ed. Philipp Wolfgang Stockhammer, (Springer-Verlag Berlin Heidelberg, 2012), 133-157.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</a></span></td>
        	</tr>
              <tr>
  <td class="number">32</td>
  <td class="reference"><a name="fn32"></a>Baker, S., “Will We all be Speaking Hinglish One Day?”, <em> British Council, </em> 2015, accessed 3 November 2021 <ahref=”https://www.britishcouncil.org/voices-magazine/will-we-all-be-speaking-hinglish-one-day”target="_blank”>https://www.britishcouncil.org/voices-magazine/will-we-all-be-speaking-hinglish-one-day</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref32">&uarr;</a></span></td>

  	</tr>
              <tr>
  <td class="number">33</td>

  	<td class="reference"><a name="fn33"></a>Lawrence, “Beyond the Graphic User Interface”.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</a></span></td>

        </tr>
              <tr>
  <td class="number">34</td>
        	<td class="reference"><a name="fn34"></a>Skiba, R., “Code switching as a Countenance of Language Interference”, <em> The Internet TESL Journal, </em> 3, no. 10 (1997): 1–6.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">35</td>
  <td class="reference"><a name="fn35"></a>Crystal, D. The Cambridge <em> Encyclopedia of Language, </em> (Cambridge University Press, 1987), 372-375.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref35">&uarr;</a></span></td>
         	</tr>
  <tr>
        	<td class="number">36</td>
  <td class="reference"><a name="fn36"></a>“The Challenge of Spoken Language”, 1–21.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref36">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">37</td>
  <td class="reference"><a name="fn37"></a>Martin, R., “Common Voice Languages and Accent Strategy v5”, <em> Mozilla, </em> 2020, accessed 3 November 2021,<ahref=”https://discourse.mozilla.org/t/common-voice-languages-and-accent-strategy-v5/56555”target="_blank”>,https://discourse.mozilla.org/t/common-voice-languages-and-accent-strategy-v5/56555</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref37">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">38</td>
  <td class="reference"><a name="fn38"></a>McEvoy, J., “A Few Differences Between French Spoken in Québec and France”, <em> British Council, </em> 2017, accessed 3 November 2021<ahref=”https://www.britishcouncil.org/voices-magazine/few-differences-between-french-spoken-quebec-and-france target="_blank”>https://www.britishcouncil.org/voices-magazine/few-differences-between-french-spoken-quebec-and-france</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref38">&uarr;</a></span></td>
        	</tr>
  </tr>
  <tr>
        	<td class="number">39</td>
  <td class="reference"><a name="fn39"></a>“Why Common Voice?”, <em> Common Voice, </em> <ahref=”https://commonvoice.mozilla.org/en/about”target="_blank”>https://commonvoice.mozilla.org/en/about</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref39">&uarr;</a></span></td>

        	</tr>
  <tr>
        	<td class="number">40</td>
  <td class="reference"><a name="fn40"></a>“Why Common Voice?”, <em> Common Voice. </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref40">&uarr;</a></span></td>

        	</tr>
  <tr>
        	<td class="number">41</td>
  <td class="reference"><a name="fn41"></a>Martin, R., “Common Voice Languages and Accent Strategy v5”, <em> Mozilla </em>. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref41">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">42</td>
  <td class="reference"><a name="fn42"></a>Paul, S. “Voice Is the Next Big Platform, Unless You Have an Accent”, <em> Wired, </em> 2017,<ahref=”https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/”target="_blank”>https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref42">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">43</td>
  <td class="reference"><a name="fn43"></a>Paul, S. “Voice Is the Next Big Platform, Unless You Have an Accent”, <em> Wired, </em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref43">&uarr;</a></span></td>

        	</tr>


  <tr>
        	<td class="number">44</td>
  <td class="reference"><a name="fn44"></a>Ali,“Why Common Voice?”, <em> Common Voice. </em> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref44">&uarr;</a></span></td>
        	</tr>
  <tr>
        	<td class="number">45</td>
  <td class="reference"><a name="fn45"></a>Ali,“Why Common Voice?”, <em> Common Voice. </em> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref45">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">46</td>
  <td class="reference"><a name="fn46"></a>Branson, M., “Help Create Common Voice’s First Target Segment”, <em> Mozilla, </em> 2020, accessed 3 November 2020<ahref=”https://discourse.mozilla.org/t/help-create-common-voices-first-target-segment/59587”target="_blank”>.https://discourse.mozilla.org/t/help-create-common-voices-first-target-segment/59587</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref46">&uarr;</a></span></td>
  	</tr>
  	</tr>
  <tr>
        	<td class="number">47</td>
  <td class="reference"><a name="fn47"></a>Branson, M., “More Data, More Languages, and Introducing our First Target Segment!”, <em> Mozilla </em>, 2020, accessed 3 November 2021 <ahref=”https://discourse.mozilla.org/t/common-voice-dataset-release-mid-year-2020/62938”target="_blank”>https://discourse.mozilla.org/t/common-voice-dataset-release-mid-year-2020/62938</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref47">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">48</td>
  <td class="reference"><a name="fn48"></a>“Mission”, <em> Linguistic Data Consortium, </em>accessed 3 November 2021,<ahref=”https://www.ldc.upenn.edu/about/mission”target="_blank”> https://www.ldc.upenn.edu/about/mission</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref48">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">49</td>
  <td class="reference"><a name="fn49"></a>“About LDC”, <em> Linguistic Data Consortium, </em>accessed 3 November 2021,<ahref=”https://www.ldc.upenn.edu/about/”target="_blank”> https://www.ldc.upenn.edu/about/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref49">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">50</td>
  <td class="reference"><a name="fn50"></a>“Other Collaborations” <em> Linguistic Data Consortium, </em>accessed 3 November 2021,<ahref=”https://www.ldc.upenn.edu//collaborations/other”target="_blank”> https://www.ldc.upenn.edu/collaborations/other</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref50">&uarr;</a></span></td>
  	</tr>

  <tr>
        	<td class="number">51</td>
  <td class="reference"><a name="fn51"></a>“Tagset for Indian Languages”, <em> Sketch Engine, </em> accessed 3November2021<ahref=”https://www.sketchengine.eu/tagset-indian-languages/”target="_blank”>https://www.sketchengine.eu/tagset-indian-languages/</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref51">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">52</td>
  <td class="reference"><a name="fn52"></a>“VoxForge”, <em> VoxForge, </em><ahref=”http://www.voxforge.org/.”target="_blank”>http://www.voxforge.org/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref52">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">53</td>
  <td class="reference"><a name="fn53"></a>“The M-AILABS Speech Dataset”, <em> Caito,</em> accessed 3 November 2021<ahref=”https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/.“target="_blank”>https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/.</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref53">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">54</td>
  <td class="reference"><a name="fn54"></a>“About Us”, <em> National Platform for Language Technology </em> <ahref=”https://nplt.in/demo/about-nplt,”target="_blank”>https://nplt.in/demo/about-nplt,</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref54">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">55</td>
  <td class="reference"><a name="fn55"></a>“Voices”, <em> Indic TTS </em> <ahref=” https://www.iitm.ac.in/donlab/tts/voices.php“target="_blank”>https://www.iitm.ac.in/donlab/tts/voices.php</a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref55">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">56</td>
  <td class="reference"><a name="fn56"></a>“Android Applications”, <em> Indic TTS </em> <ahref=”https://www.iitm.ac.in/donlab/tts/androidapp.php”target="_blank”>https://www.iitm.ac.in/donlab/tts/androidapp.php </a> &nbsp;&nbsp;<span class="internal-nav"><a href="#ref56">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">57</td>
  <td class="reference"><a name="fn57"></a>”Lawrence, “Beyond the Graphic User Interface”.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref57">&uarr;</a></span></td>
  	</tr>
  <tr>
        	<td class="number">58</td>
  <td class="reference"><a name="fn58"></a>Hernandez, “How Voice Recognition Systems” <em> Splinter </em>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref58">&uarr;</a></span></td>



</tr>
</table>
    </div>
  </div>

      <div class="six wide column empty">
      </div>


    </div>
  </div>
  <!-- Footer -->
  <div class="footer">
    <div class="ui container four column stackable grid">
      <div class="one wide column empty">
      </div>
      <div class="five wide column">
        <h3>About the Study</h3>
        <p>We believe that voice interfaces have the potential to democratise the use of the internet by addressing limitations related to reading and writing on digital text-only platforms and devices. This report examines the current landscape of voice interfaces in India, with a focus on concerns related to privacy and data protection, linguistic barriers, and accessibility for persons with disabilities (PwDs). This project was undertaken with support by the Mozilla Corporation.</p>
      </div>
      <div class="five wide column">
        <h3>Research Team</h3>
        <p>Research: Shweta Mohandas, Saumyaa Naidu, Deepika NS, Divya Pinheiro, Sweta Bisht </p>
        <p><em>Conceptualisation, Planning, and Research Inputs</em> Sumandro Chattapadhyay, Puthiya Purayil Sneha</p>
        <p><em>Illustration</em> Kruthika NS</p>
        <p><em>Website Design</em> Saumyaa Naidu</p>
        <p><em>Website Development</em> Sumandro Chattapadhyay, Pranav M Bidare</p>
        <p><em>Review and Editing</em> Puthiya Purayil Sneha, Divyank Katira, Pranav M Bidare, Torsha Sarkar, Pallavi Bedi, Divya Pinheiro</p>
        <p><em>Copy Editing</em> The Clean Copy</p>
      </div>
      <div class="four wide column">
        <h3>Copyright and Credits</h3>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2021<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a><br/><a href="https://fonts.google.com/specimen/Barlow" target="_blank">Barlow</a> and <a href="https://fonts.google.com/specimen/Open+Sans" target="_blank">Open Sans</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/cis-india/mozvoice" target="_blank">GitHub</a></p>
      </div>
      <div class="one wide column empty">
      </div>
      <div class="sixteen wide column">
        <div style="float: center; clear: both;">
        <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons" style="float: center; clear: both;">
          <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
	</div>
      </div>
    </div>
  </div>
</body>
</html>
